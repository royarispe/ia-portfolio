---
title: "CNNs y Transfer Learning: Construcci√≥n, Entrenamiento y Fine-Tuning"
date:
---

# CNNs y Transfer Learning con TensorFlow/Keras

---

## üìù Contexto

En este noveno pr√°ctico nos adentramos en uno de los pilares del Deep Learning moderno para Computer Vision:  
las **Redes Neuronales Convolucionales (CNNs)** y las t√©cnicas de **Transfer Learning**.

El objetivo fue comparar dos enfoques muy utilizados en la industria:

1. **Entrenar una CNN desde cero**, utilizando √∫nicamente el dataset CIFAR-10.  
2. **Aprovechar un modelo pre-entrenado en ImageNet**, congelando sus capas iniciales y usando sus caracter√≠sticas como extractor visual.

Adem√°s, como extensi√≥n, realic√© un peque√±o experimento de **fine-tuning**, ajustando parcialmente las capas del modelo preentrenado para observar su impacto en el rendimiento.

El trabajo fue realizado en Google Colab.

## üéØ Objetivos

En este pr√°ctico busqu√©:

- Comprender la estructura y funcionamiento de una **CNN** aplicada a clasificaci√≥n de im√°genes.
- Entrenar una red convolucional **desde cero** utilizando CIFAR-10 como dataset base.
- Implementar **Transfer Learning** usando modelos pre-entrenados de Keras Applications.
- Comparar el rendimiento entre una CNN de arquitectura simple y un modelo basado en ImageNet.
- Aplicar t√©cnicas de **fine-tuning** para ajustar parcialmente las capas del modelo preentrenado.
- Analizar m√©tricas clave de desempe√±o: accuracy, loss, reporte de clasificaci√≥n y comportamiento por √©poca.
- Explorar un peque√±o experimento libre que permita extender el pr√°ctico sin volverlo demasiado extenso.

## üöÄ Desarrollo

### üß† Parte 1 ‚Äì Dataset CIFAR-10 y Preprocesamiento

Para este pr√°ctico se utiliz√≥ el dataset **CIFAR-10**, un conjunto de 60.000 im√°genes a color de 32√ó32 p√≠xeles pertenecientes a 10 clases distintas.  
Es un dataset muy usado en investigaci√≥n y docencia porque, aunque peque√±o, presenta variabilidad suficiente para poner a prueba modelos convolucionales y de transfer learning.

Los pasos de preparaci√≥n fueron los siguientes:

1. **Carga del dataset** desde `keras.datasets.cifar10`.
2. **Normalizaci√≥n** de las im√°genes al rango `[0, 1]`, lo que facilita la convergencia del modelo.
3. **Conversi√≥n de etiquetas** a formato one-hot encoding utilizando `to_categorical`.
4. Inspecci√≥n de las dimensiones finales:
   - `x_train`: 50.000 im√°genes  
   - `x_test`: 10.000 im√°genes  
   - tama√±o de cada imagen: `32√ó32√ó3`
   - n√∫mero de clases: 10

Este preprocesamiento dej√≥ los datos listos para entrenar tanto una **CNN desde cero** como para alimentar un **modelo preentrenado** dentro de las Keras Applications.

### üèóÔ∏è Parte 2 ‚Äì Construyendo una CNN simple desde cero

Como primer modelo entrenado en este pr√°ctico, implement√© una **CNN peque√±a** utilizando √∫nicamente capas convolucionales, max pooling y un clasificador denso al final.  
El objetivo de esta arquitectura base fue establecer una referencia clara para comparar luego contra la estrategia de transfer learning.

La arquitectura utilizada fue la siguiente:

1. **Bloque Convolucional 1**
   - `Conv2D(32, kernel_size=3, padding='same')`
   - Activaci√≥n `ReLU`
   - `MaxPooling2D(pool_size=2)`

2. **Bloque Convolucional 2**
   - `Conv2D(64, kernel_size=3, padding='same')`
   - Activaci√≥n `ReLU`
   - `MaxPooling2D(pool_size=2)`

3. **Clasificador final**
   - `Flatten()`
   - `Dense(512, activation='relu')`
   - `Dense(10, activation='softmax')`

El modelo fue compilado con:
- Optimizador **Adam (lr=0.001)**
- P√©rdida **categorical_crossentropy**
- M√©trica **accuracy**

Aunque esta CNN es relativamente peque√±a comparada con modelos modernos, resulta muy √∫til para:

- entender c√≥mo fluyen los datos en arquitecturas convolucionales,
- observar capacidad de aprendizaje sin preentrenamiento,
- y establecer un baseline honesto para contrastar con modelos preentrenados m√°s complejos.

Este modelo fue entrenado durante 10 √©pocas con early stopping para evitar sobreajuste.

### üéØ Parte 3 ‚Äì Transfer Learning con MobileNetV2

El segundo enfoque del pr√°ctico consisti√≥ en aplicar **Transfer Learning** utilizando modelos preentrenados de `Keras Applications`, entrenados originalmente sobre ImageNet.  
En este caso us√© **MobileNetV2**, un modelo liviano, eficiente y compatible con im√°genes de 32√ó32, lo que lo hace ideal para CIFAR-10.

El procedimiento seguido fue:

1. **Carga del modelo base preentrenado**
   - `MobileNetV2(weights="imagenet", include_top=False, input_shape=(32,32,3))`
   - Se eliminaron las capas finales (clasificador ImageNet).
   - Se congelaron todas sus capas para que funcionara √∫nicamente como extractor de caracter√≠sticas.

2. **Capas a√±adidas por encima**
   - `Flatten()`
   - `Dense(10, activation='softmax')` como clasificador final para CIFAR-10.

3. **Compilaci√≥n del modelo**
   - Optimizador **Adam**, con un learning rate m√°s bajo (`0.001`) debido a la naturaleza preentrenada del modelo.
   - P√©rdida `categorical_crossentropy`.

4. **Entrenamiento**
   - El modelo fue entrenado durante 10 √©pocas.
   - EarlyStopping control√≥ el sobreajuste y evit√≥ entrenar de m√°s.
   - Al utilizar caracter√≠sticas extra√≠das de un modelo robusto como MobileNetV2, se obtuvo un rendimiento notablemente superior al modelo CNN desde cero.

Este modelo actu√≥ como un excelente ejemplo del poder del transfer learning:  
incluso sin entrenar las capas convolucionales, el modelo logr√≥ aprovechar representaciones visuales aprendidas previamente para mejorar la precisi√≥n sobre CIFAR-10.

### üî¨ Parte 4 ‚Äì Experimento Extra: Fine-Tuning de MobileNetV2

Como actividad de investigaci√≥n libre, realic√© un peque√±o experimento para observar c√≥mo cambia el rendimiento de un modelo de transfer learning cuando se habilita **fine-tuning** en lugar de mantener todas sus capas congeladas.

El procedimiento consisti√≥ en:

1. **Evaluar el modelo preentrenado original**  
   MobileNetV2 con todas las capas congeladas actu√≥ como baseline.  
   Este modelo ya ofrec√≠a una precisi√≥n superior a la CNN simple gracias a las caracter√≠sticas de ImageNet.

2. **Crear un segundo modelo MobileNetV2 id√©ntico**, pero:
   - descongelar las **√∫ltimas 20 capas** del modelo base,
   - recompilar con un learning rate m√°s bajo (`0.0001`),
   - entrenarlo durante solo 5 √©pocas para evitar tiempos largos.

3. **Comparar** ambas versiones:
   - MobileNetV2 congelado (solo clasificador entrenado),
   - MobileNetV2 con fine-tuning parcial.

El resultado fue claro:  
el modelo con fine-tuning logr√≥ una mejora adicional en accuracy, demostrando que permitir que las capas profundas del modelo se ajusten al dominio de CIFAR-10 aporta beneficios incluso con pocas √©pocas de entrenamiento.

En la secci√≥n evidencias se podr√° observar de forma visual los resultados obtenidos.

Estas visualizaciones permiten apreciar f√°cilmente la diferencia en rendimiento entre ambos enfoques y justifican el uso del fine-tuning cuando se dispone de recursos adicionales.

## üì∏ Evidencias

[Enlace al notebook](https://colab.research.google.com/drive/1nbWu38-umslYivVlAS-d-wzwWCsPCi2E?usp=sharing)

A continuaci√≥n incluyo las visualizaciones m√°s relevantes obtenidas durante el pr√°ctico.  
Estas im√°genes provienen directamente del notebook ejecutado en Google Colab y permiten apreciar claramente el comportamiento de cada modelo.

### 1Ô∏è‚É£ CNN simple
Se observa c√≥mo la red desde cero mejora progresivamente, aunque su capacidad limitada hace que la accuracy de validaci√≥n quede por debajo del modelo preentrenado.

![CNN](../assets/ut2_p9_1.png){ width="480" }

### 2Ô∏è‚É£ Modelo MobileNetV2 preentrenado
El modelo con transfer learning converge m√°s r√°pido y alcanza una precisi√≥n sustancialmente mayor sin necesidad de entrenar sus capas convolucionales.

![Transfer_learning](../assets/ut2_p9_2.png){ width="480" }

### 3Ô∏è‚É£ Comparaci√≥n entre ambos modelos.

![Comparaci√≥n](../assets/ut2_p9_3.png){ width="480" }

### 3Ô∏è‚É£ Comparaci√≥n visual del experimento de Fine-Tuning
Incluye dos elementos clave:

- **Curvas de accuracy del modelo fine-tuneado**, donde se ve c√≥mo sigue mejorando incluso con pocas √©pocas.
- **Gr√°fico de barras Frozen vs Fine-Tuned**, que muestra claramente el aumento de precisi√≥n cuando se descongelan las √∫ltimas capas del modelo base.

![exp_finetuning](../assets/ut2_p9_4.png){ width="480" }

Estas evidencias permiten visualizar de forma directa el impacto del transfer learning y del fine-tuning en comparaci√≥n con una CNN entrenada desde cero.

## üí° Reflexi√≥n

Este pr√°ctico fue fundamental para entender c√≥mo se aplican las CNNs y el Transfer Learning en problemas reales de visi√≥n por computadora. La comparaci√≥n entre una red convolucional construida desde cero y un modelo preentrenado dej√≥ varios aprendizajes claros:

- Las **CNN simples** permiten comprender la mec√°nica b√°sica del procesamiento visual, pero su capacidad es limitada cuando el dataset es complejo o variado.
- El **Transfer Learning** demostr√≥ ser extremadamente eficaz: incluso sin entrenar las capas convolucionales del modelo base, MobileNetV2 logr√≥ un rendimiento notablemente superior con mucho menos tiempo de entrenamiento.
- El experimento adicional de **fine-tuning** confirm√≥ que ajustar parcialmente las capas superiores del modelo preentrenado aporta un beneficio extra, ya que permite adaptar mejor las caracter√≠sticas aprendidas del dominio de ImageNet al dominio espec√≠fico de CIFAR-10.
- Tambi√©n pude observar c√≥mo la elecci√≥n del **learning rate**, el uso de **early stopping** y la estrategia de congelar/descongelar capas influyen directamente en la estabilidad y convergencia del entrenamiento.

En resumen, este pr√°ctico consolid√≥ la idea de que el aprendizaje profundo no siempre implica entrenar redes desde cero: muchas veces, la mejor estrategia es apoyarse en modelos robustos ya entrenados y adaptarlos a nuevas tareas. Esta combinaci√≥n de eficiencia, rendimiento y buenas pr√°cticas es clave en proyectos reales de machine learning.

## üìö Referencias

- [Dataset CIFAR-10 en Keras](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10)
- [Keras Sequential Model](https://www.tensorflow.org/guide/keras/sequential_model)
- [Capa Conv2D (Convoluciones)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)
- [Capa MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D)
- [MobileNetV2 ‚Äì Keras Applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2)
- [Keras Optimizers (Adam, SGD, RMSprop)](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)
- [Callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)
- [Gu√≠a de Transfer Learning en Keras](https://keras.io/guides/transfer_learning/)
- [Evaluaci√≥n de Modelos en Keras (`model.evaluate`)](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)


