---
title: "De Perceptr√≥n a Redes Neuronales: XOR, MLPs y Deep Learning"
date:
---

# De Perceptr√≥n a Redes Neuronales: XOR, MLPs y Deep Learning

---

## üìù Contexto

En este s√©ptimo pr√°ctico dimos un salto fundamental en la materia: pasamos de los modelos lineales cl√°sicos a las bases del **Deep Learning**.

El trabajo comenz√≥ implementando desde cero un **Perceptr√≥n simple** para entender su funcionamiento interno (pesos, bias, funci√≥n de activaci√≥n escal√≥n). Sin embargo, el punto de inflexi√≥n fue chocar con su gran limitaci√≥n hist√≥rica: la incapacidad de resolver problemas no linealmente separables, como la compuerta **XOR**.

Para superar esto, evolucionamos hacia **Redes Neuronales Multicapa (MLP)**, primero utilizando `scikit-learn` para entender la arquitectura b√°sica, y luego migrando a frameworks profesionales como **TensorFlow/Keras** y **PyTorch Lightning**.

Este pr√°ctico fue clave para entender por qu√© necesitamos "capas ocultas" y c√≥mo herramientas modernas automatizan el c√°lculo de gradientes y la retropropagaci√≥n (*backpropagation*) que antes eran manuales.

Como siempre, el c√≥digo y las visualizaciones fueron generados en Google Colab.

---

## üéØ Objetivos

En esta pr√°ctica busqu√©:

- Comprender la matem√°tica y l√≥gica detr√°s del **Perceptr√≥n Simple**.
- Visualizar las **fronteras de decisi√≥n** lineales y entender sus l√≠mites (problema XOR).
- Implementar una **Red Neuronal Multicapa (MLP)** para resolver problemas no lineales.
- Comparar implementaciones simples (`sklearn`) vs. profesionales (`TensorFlow`, `PyTorch`).
- Analizar curvas de aprendizaje (*Loss* y *Accuracy*) para detectar convergencia o overfitting.
- Entender el rol de las funciones de activaci√≥n (`ReLU`, `Sigmoid`, `Tanh`) y optimizadores (`Adam`).

---

## üöÄ Desarrollo

### üß† Parte 1 ‚Äì El Perceptr√≥n y la L√≥gica Booleana

[cite_start]Para comenzar, implement√© desde cero la funci√≥n b√°sica del perceptr√≥n: una suma ponderada de las entradas m√°s un sesgo (*bias*), pasada por una funci√≥n de activaci√≥n escal√≥n[cite: 6, 7].

El objetivo fue probar si este modelo simple pod√≠a "aprender" las compuertas l√≥gicas b√°sicas. Ajustando manualmente los pesos ($w_1, w_2$) y el sesgo ($b$), obtuve los siguientes resultados:

#### 1Ô∏è‚É£ **Compuerta AND**
Requiere que ambas entradas sean 1 para activarse.
- [cite_start]**Configuraci√≥n:** $w_1=0.5, w_2=0.5, bias=-0.7$[cite: 62].
- **Resultado:** El bias negativo alto act√∫a como un filtro estricto. [cite_start]El perceptr√≥n traz√≥ una l√≠nea que separ√≥ perfectamente el (1,1) del resto[cite: 102].

#### 2Ô∏è‚É£ **Compuerta OR**
Es m√°s permisiva, se activa con cualquier 1.
- [cite_start]**Configuraci√≥n:** $w_1=0.5, w_2=0.5, bias=-0.2$[cite: 130].
- **Resultado:** Al subir el bias (hacerlo menos negativo), la l√≠nea de decisi√≥n se desplaz√≥, permitiendo que cualquiera de las entradas activara la neurona.

#### 3Ô∏è‚É£ **Compuerta NOT**
Un inversor simple de una sola entrada.
- [cite_start]**Configuraci√≥n:** $w_1=-1.0, bias=0.5$[cite: 192].
- **Resultado:** Peso negativo para invertir la entrada. Funcion√≥ perfecto.

A continuaci√≥n, una visualizaci√≥n de c√≥mo el perceptr√≥n separ√≥ las clases en el caso AND:

![Visualizaci√≥n del Perceptr√≥n para AND](../assets/ut2_p7_1.png){ width="480" }

---

### ‚ùå Parte 2 ‚Äì El l√≠mite: el problema XOR

Despu√©s del √©xito con las compuertas b√°sicas, intent√© resolver el problema **XOR (O Exclusivo)**. Aqu√≠ la salida debe ser 1 solo si las entradas son diferentes (0,1 o 1,0).

[cite_start]Realic√© varios intentos manuales modificando los pesos y el bias para tratar de encontrar una l√≠nea que separara los puntos, pero fue **matem√°ticamente imposible**[cite: 314].

- [cite_start]**Mejor intento:** 75% de accuracy (3 de 4 aciertos)[cite: 318].
- **El problema:** Los puntos de la clase 0 (0,0 y 1,1) y los de la clase 1 (0,1 y 1,0) est√°n dispuestos diagonalmente opuestos.
- [cite_start]**Conclusi√≥n visual:** No existe ninguna l√≠nea recta √∫nica que pueda dejar a los puntos rojos de un lado y a los azules del otro[cite: 370].

Esta limitaci√≥n visualiz√≥ perfectamente por qu√© el perceptr√≥n simple cay√≥ en desuso en los a√±os 60: **solo sirve para problemas linealmente separables**.

La siguiente imagen muestra c√≥mo la l√≠nea recta falla inevitablemente en clasificar los 4 puntos del XOR:

![Fallo del Perceptr√≥n en XOR](../assets/ut2_p7_2.png){ width="480" }

---

### üåä Parte 3 ‚Äì La soluci√≥n: Redes Neuronales Multicapa (MLP)

Dado que una sola l√≠nea recta no era suficiente, la soluci√≥n fue agregar **capas ocultas** para permitir que el modelo aprendiera fronteras de decisi√≥n no lineales.

Utilic√© la clase `MLPClassifier` de `sklearn` para construir una peque√±a red neuronal:

- **Arquitectura:** 2 entradas $\rightarrow$ 4 neuronas ocultas $\rightarrow$ 1 salida.
- **Activaci√≥n:** `tanh` (tangente hiperb√≥lica) para introducir no-linealidad.
- **Optimizador:** `Adam`.

**El resultado fue inmediato:** La red logr√≥ un **100% de Accuracy** en el problema XOR.

Al graficar la superficie de decisi√≥n, la diferencia fue visualmente impactante. Mientras el perceptr√≥n intentaba trazar una recta in√∫til, el MLP gener√≥ una **curva suave** que aislaba perfectamente las zonas azules de las rojas. Esto confirm√≥ que al combinar m√∫ltiples neuronas, la red puede "doblar" el espacio para clasificar correctamente datos complejos.

![Comparaci√≥n Perceptr√≥n vs MLP](../assets/ut2_p7_3.png){ width="480" }

---

### ü§ñ Parte 4 ‚Äì Deep Learning Profesional con TensorFlow

Una vez entendida la teor√≠a con `sklearn`, pas√© a un entorno profesional utilizando **TensorFlow** y **Keras**. El objetivo era resolver un problema de clasificaci√≥n m√°s realista (dataset sint√©tico con 1000 muestras y 20 caracter√≠sticas).

Dise√±√© una arquitectura secuencial (`Sequential`) m√°s robusta:

1.  **Capa Oculta 1:** 64 neuronas con activaci√≥n `ReLU`.
2.  **Capa Oculta 2:** 32 neuronas con activaci√≥n `ReLU`.
3.  **Capa de Salida:** 1 neurona con activaci√≥n `Sigmoid` (para obtener una probabilidad entre 0 y 1).

El entrenamiento se realiz√≥ durante 30 √©pocas monitoreando dos m√©tricas clave:

- **Loss (P√©rdida):** Baj√≥ consistentemente hasta casi 0.
- **Accuracy (Precisi√≥n):** Alcanz√≥ el **99.9%** en entrenamiento y **92.3%** en validaci√≥n.

Este paso fue crucial para entender conceptos como **epochs** (cu√°ntas veces la red ve los datos) y **batch_size** (lotes de procesamiento), que en `sklearn` suelen estar m√°s abstra√≠dos.

![Curvas de Aprendizaje TensorFlow](../assets/ut2_p7_4.png){ width="480" }

---

### ‚ö° Parte 5 ‚Äì PyTorch Lightning: Estructura y modularidad

Para cerrar la parte t√©cnica, explor√© **PyTorch Lightning**. A diferencia de Keras (que es muy directo), PyTorch requiere definir una clase que hereda de `pl.LightningModule`.

Esto fue interesante porque me oblig√≥ a estructurar el c√≥digo de manera mucho m√°s ordenada, definiendo expl√≠citamente:
- El **`forward pass`** (c√≥mo fluyen los datos).
- El **`training_step`** (c√°lculo de p√©rdida en entrenamiento).
- El **`test_step`** (evaluaci√≥n y c√°lculo de accuracy).
- La configuraci√≥n del optimizador (`Adam`).

Aunque requiere escribir m√°s l√≠neas de c√≥digo que `sklearn` o `keras.Sequential`, la ventaja es la claridad: sabes exactamente qu√© est√° pasando en cada paso del entrenamiento. Implement√© una red similar a la anterior y logr√© replicar los buenos resultados, confirmando que la arquitectura es robusta independientemente del framework.

---

## üì∏ Evidencias

[Enlace al notebook](https://colab.research.google.com/drive/1MOKSu93vYAyQafwYsX4CJJ-R08GAOQjG?usp=sharing)

---

## üí° Reflexi√≥n

Este pr√°ctico fue clave para desmitificar c√≥mo "piensan" las redes neuronales.

Lo m√°s impactante fue ver visualmente la **limitaci√≥n del Perceptr√≥n**. Una cosa es leer que "no resuelve problemas no lineales" y otra muy distinta es ver c√≥mo la l√≠nea verde intenta desesperadamente separar el XOR y falla. Entend√≠ que agregar **capas ocultas** no es solo "hacer la red m√°s grande", sino darle la capacidad de **doblar el espacio** para crear fronteras de decisi√≥n complejas.

Respecto a las herramientas, me llevo una gu√≠a clara de cu√°ndo usar cada una:
- **Scikit-learn (MLP):** Ideal para pruebas r√°pidas en datos tabulares simples donde no necesito control sobre el entrenamiento. Es una "caja negra" eficiente.
- **TensorFlow/Keras:** El est√°ndar para producci√≥n. Me gust√≥ poder ver las curvas de *Loss* en tiempo real y controlar los *epochs*.
- **PyTorch Lightning:** Se siente m√°s "verborr√°gico" al principio, pero entiendo su valor para investigaci√≥n o arquitecturas personalizadas donde necesitas control total sobre el bucle de entrenamiento.

Finalmente, valid√© la importancia de las funciones de activaci√≥n. Sin `ReLU` o `Tanh` en las capas ocultas, no importa cu√°ntas capas agregue, la red seguir√≠a comport√°ndose como un modelo lineal. La no-linealidad es el ingrediente secreto del Deep Learning.

---

## üìö Referencias

- [Documentaci√≥n de MLPClassifier (Scikit-learn)](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [TensorFlow Keras Sequential Model](https://www.tensorflow.org/guide/keras/sequential_model)
- [PyTorch Lightning Documentation](https://lightning.ai/docs/pytorch/stable/)
- [Playground de TensorFlow (muy √∫til para visualizar)](https://playground.tensorflow.org/)
- [Explicaci√≥n del problema XOR y Perceptrones](https://en.wikipedia.org/wiki/Perceptron#Limitations)