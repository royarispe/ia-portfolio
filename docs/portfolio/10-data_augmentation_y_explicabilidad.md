---
title: "Data Augmentation Avanzado y Explicabilidad en Computer Vision"
date:
---

# Data Augmentation Avanzado & Explicabilidad en Deep Learning

---

## üìù Contexto

En esta ocasi√≥n trabaj√© con uno de los datasets m√°s conocidos para clasificaci√≥n de flores: **Oxford Flowers102**, un conjunto de im√°genes de alta resoluci√≥n con 102 clases, alta variabilidad y desbalance natural entre clases. 

El objetivo fue construir un pipeline robusto de **data augmentation avanzado** para mejorar la capacidad de generalizaci√≥n del modelo, y luego incorporar t√©cnicas de **explicabilidad** que permitan interpretar qu√© regiones de la imagen influyen en la predicci√≥n del modelo.

Adem√°s de aplicar augmentations comunes (flip, rotaci√≥n, zoom, brillo, contraste), explor√© t√©cnicas modernas de explicabilidad como **GradCAM** e **Integrated Gradients**, fundamentales para validar modelos en escenarios sensibles como identificaci√≥n bot√°nica.

El trabajo se desarroll√≥ completamente en Google Colab, utilizando TensorFlow, Keras y TensorFlow Datasets.

## üéØ Objetivos

En este pr√°ctico me propuse:

- Trabajar con un dataset complejo y realista: **Oxford Flowers102**, con im√°genes de alta resoluci√≥n y 102 clases.
- Implementar **pipelines de data augmentation avanzado**, combinando transformaciones geom√©tricas y fotom√©tricas.
- Comparar un pipeline baseline vs. uno con augmentations para evaluar impacto en la robustez del modelo.
- Entrenar un modelo basado en **EfficientNetB0** utilizando transfer learning.
- Visualizar c√≥mo reacciona el modelo ante diferentes perturbaciones del dataset.
- Aplicar t√©cnicas de explicabilidad modernas:
  - **GradCAM**, para identificar qu√© regiones de la imagen activan al modelo.
  - **Integrated Gradients**, para analizar contribuciones de p√≠xeles a la predicci√≥n.
- Generar evidencias claras que permitan evaluar el comportamiento del modelo y detectar posibles fallos o sesgos visuales.

## üöÄ Desarrollo

### üå∏ Parte 1 ‚Äì Dataset Oxford Flowers102

Para este pr√°ctico utilizamos **Oxford Flowers102**, un dataset considerablemente m√°s desafiante que CIFAR-10:

- 102 clases de flores del Reino Unido  
- Im√°genes de alta resoluci√≥n  
- Variabilidad significativa en iluminaci√≥n, √°ngulo, enfoque y fondo  
- Desbalance natural (algunas clases tienen m√°s del doble de im√°genes que otras)

El dataset fue cargado mediante **TensorFlow Datasets (TFDS)**, lo cual simplifica tanto la descarga como el acceso a las anotaciones y metadatos.  
Luego, cada imagen se **redimension√≥ a 224√ó224** para ser compatible con arquitecturas modernas como EfficientNet.

Se definieron *subsets* para acelerar la experimentaci√≥n:

- **Training:** 5000 im√°genes  
- **Test:** 1000 im√°genes  

Esto permiti√≥ iterar m√°s r√°pido sin perder la complejidad del dataset.

---

### üß± Parte 2 ‚Äì Pipelines de procesamiento

Se crearon dos pipelines distintos para comparar el impacto del data augmentation:

#### 1Ô∏è‚É£ Pipeline **Baseline**
Incluye √∫nicamente:
- batching
- prefetch
- normalizaci√≥n mediante `preprocess_input` (EfficientNet)

Este pipeline sirve como punto de comparaci√≥n para ver c√≥mo se comporta el modelo sin perturbaciones adicionales.

#### 2Ô∏è‚É£ Pipeline **Augmented** (Data Augmentation avanzado)
Construido con la capa `keras.Sequential` y compuesto por:

- **Transformaciones geom√©tricas:**  
  `RandomFlip`, `RandomRotation`, `RandomZoom`, `RandomTranslation`
- **Transformaciones fotom√©tricas:**  
  `RandomBrightness`, `RandomContrast`

Estas t√©cnicas generan nuevas versiones realistas de las im√°genes, lo que ayuda al modelo a ser m√°s robusto ante:
- cambios de luz,  
- variaciones de √°ngulo,  
- zooms involuntarios,  
- desplazamientos,  
- y fluctuaciones de contraste.

Finalmente, se incluy√≥ una funci√≥n para **visualizar el efecto de los augmentations**, generando 9 versiones transformadas de una misma imagen. Esta visualizaci√≥n fue muy √∫til para verificar que las transformaciones fueran razonables y no destruyeran informaci√≥n importante sobre la flor.

### ü§ñ Parte 2 ‚Äì Modelo basado en EfficientNetB0 (Transfer Learning)

Para resolver el desaf√≠o de clasificar las 102 especies de flores, utilic√© un modelo de **Transfer Learning** basado en **EfficientNetB0**.  
Este modelo es actualmente uno de los m√°s eficientes en relaci√≥n *capacidad ‚Üî costo computacional*, lo cual lo hace ideal para ser usado en Google Colab sin excederse en tiempos de entrenamiento.

#### üîß Arquitectura utilizada

1. **Modelo base preentrenado**
   - `EfficientNetB0(weights="imagenet", include_top=False)`
   - Entrada: im√°genes RGB de tama√±o `224√ó224`
   - Todas las capas se congelaron inicialmente (`trainable = False`) para entrenar solo el clasificador.

2. **Clasificador agregado por encima**
   - `GlobalAveragePooling2D()`  
     (reduce mapas de activaci√≥n a un vector compacto)
   - `Dense(NUM_CLASSES, activation='softmax')`  
     (salida final para las 102 clases)

Este enfoque permiti√≥:
- reutilizar caracter√≠sticas visuales entrenadas con millones de im√°genes,
- entrenar m√°s r√°pido,
- evitar overfitting excesivo en las primeras etapas.

#### ‚öôÔ∏è Entrenamiento

El modelo fue compilado con:

- Optimizador **Adam**
- P√©rdida **sparse categorical crossentropy** (labels enteros)
- M√©trica **accuracy**

Entren√© el modelo durante **7 √©pocas**, utilizando:
- el pipeline **augmented** para entrenamiento,  
- el pipeline **baseline** para validaci√≥n.

El uso de data augmentation ayud√≥ a contrarrestar el desbalance natural del dataset y a que el modelo se adaptara mejor a variaciones de iluminaci√≥n y √°ngulo presentes en las im√°genes reales de flores.

Tras el entrenamiento, registr√© la **mejor precisi√≥n de validaci√≥n** alcanzada, que super√≥ ampliamente a la de un modelo sin augmentations, mostrando la importancia de estas t√©cnicas para robustecer modelos de visi√≥n.

### üé® Parte 3 ‚Äì Visualizaci√≥n de Data Augmentation

Antes de entrenar el modelo, gener√© una visualizaci√≥n que aplica **nueve augmentations distintos** sobre una misma imagen.  
Esto fue clave para verificar que el pipeline avanzado:

- no distorsione excesivamente las flores,  
- genere ejemplos realistas y variados,  
- y aporte robustez ante cambios de iluminaci√≥n, zoom y orientaci√≥n.

Las transformaciones aplicadas incluyen flips, rotaciones, zooms, translations, ajustes de brillo y contraste.  
La inspecci√≥n visual confirm√≥ que el augmentation era adecuado para el dominio bot√°nico:  
las flores segu√≠an siendo reconocibles, pero suficientemente alteradas para mejorar la generalizaci√≥n del modelo.

---

### üöÄ Parte 4 ‚Äì Entrenamiento del modelo con augmentation

El modelo EfficientNetB0 fue entrenado con:

- **train_augmented** ‚Üí contiene todas las transformaciones avanzadas  
- **test_baseline** ‚Üí sin augmentations, para evaluar de forma consistente

Durante **7 √©pocas**, se observ√≥:

- mejora continua en accuracy de entrenamiento,
- una validaci√≥n bastante estable,
- ausencia de sobreajuste severo (gracias al augmentation y a EfficientNet).

El flujo de entrenamiento finaliz√≥ mostrando la **mejor accuracy obtenida**, lo que permiti√≥ evaluar claramente la utilidad del data augmentation avanzado frente a un pipeline m√°s simple.

Adem√°s, guard√© el modelo entrenado (`mi_modelo_flores.h5`) para utilizarlo con t√©cnicas de explicabilidad en las etapas siguientes.

### üîç Parte 4 ‚Äì Explicabilidad con GradCAM

Para entender mejor qu√© partes de la imagen utiliza el modelo al tomar una decisi√≥n, apliqu√© **GradCAM**, una t√©cnica que genera mapas de calor sobre las regiones con mayor contribuci√≥n a la predicci√≥n.

El procedimiento consisti√≥ en:

1. **Identificar autom√°ticamente la √∫ltima capa convolucional** del modelo EfficientNetB0.  
   Esto es necesario porque GradCAM opera sobre activaciones profundas del modelo base.

2. **Obtener una imagen del conjunto de test** y generar su predicci√≥n.

3. **Calcular el mapa de activaci√≥n GradCAM**, que resalta las zonas que influyeron m√°s en la decisi√≥n.

4. **Visualizar tres elementos clave**:
   - Imagen original  
   - Heatmap de activaci√≥n  
   - Imagen combinada (overlay)  

Esta visualizaci√≥n fue sumamente √∫til para evaluar si el modelo realmente ‚Äúmiraba‚Äù la flor o si se dejaba influenciar por el fondo o la iluminaci√≥n.  

En la mayor√≠a de los ejemplos, el modelo enfoc√≥ correctamente las regiones relevantes de la flor (p√©talos y centro), lo que indica un comportamiento saludable.  
GradCAM tambi√©n permiti√≥ identificar casos donde el modelo fallaba por fijarse demasiado en:

- hojas de fondo,  
- sombras pronunciadas,  
- o regiones perif√©ricas irrelevantes.

El uso de GradCAM aporta **transparencia**, especialmente importante en aplicaciones reales como la identificaci√≥n bot√°nica, donde es crucial justificar por qu√© el modelo lleg√≥ a una determinada predicci√≥n.

### üß† Parte 5 ‚Äì Explicabilidad con Integrated Gradients

Adem√°s de GradCAM, implement√© **Integrated Gradients (IG)**, una t√©cnica m√°s fina y matem√°ticamente fundamentada para evaluar la contribuci√≥n de cada p√≠xel a la predicci√≥n del modelo.

Mientras que GradCAM trabaja a nivel de canales y activaciones profundas, IG analiza directamente c√≥mo var√≠a la predicci√≥n al interpolar entre una imagen baseline (por ejemplo, una imagen negra) y la imagen real.

El procedimiento implementado fue:

1. **Elegir una baseline**  
   - En este caso, una imagen completamente negra, est√°ndar para IG.

2. **Interpolar entre baseline ‚Üí imagen real**  
   - Usando 50 pasos lineales, lo que permite medir gradualmente c√≥mo influye cada parte de la imagen.

3. **Calcular gradientes en cada interpolaci√≥n**  
   - Se obtiene la sensibilidad del modelo respecto a cada p√≠xel.

4. **Promediar gradientes**  
   - Esta integral aproximada produce un mapa de atribuci√≥n por p√≠xel.

5. **Visualizar resultados**  
   Se generaron tres vistas:
   - Imagen original  
   - Mapa de atribuci√≥n IG (modo *heatmap*)  
   - Overlay de IG sobre la imagen  

Este m√©todo permite entender con mayor detalle qu√© regiones espec√≠ficas del objeto (bordes, texturas, centro de la flor, p√©talos) son fundamentales para que el modelo tome una decisi√≥n.

Los resultados fueron interesantes:  
IG suele producir mapas m√°s ‚Äúfinos‚Äù que GradCAM, se√±alando patrones de color y textura relevantes que no siempre aparecen en los mapas de activaci√≥n. En algunos casos, permiti√≥ ver que el modelo prestaba atenci√≥n a patrones de p√©talos incluso cuando el fondo era complejo.  

Esto es especialmente √∫til en un dominio como bot√°nica, donde caracter√≠sticas sutiles pueden diferenciar dos especies similares.  

## üì∏ Evidencias

[Enlace al notebook](https://colab.research.google.com/drive/1Krc0hbFhy7XHT_0fKsRwN3sU65aPKve-?usp=sharing)

A continuaci√≥n se presentan las principales visualizaciones generadas durante el pr√°ctico, las cuales permitieron evaluar el comportamiento del modelo tanto en entrenamiento como en explicabilidad.

---

### 1Ô∏è‚É£ Visualizaci√≥n de Data Augmentation

Se generaron nueve versiones distintas de una misma imagen utilizando el pipeline de augmentations avanzados.  
Esto permiti√≥ inspeccionar:

- variaciones de rotaci√≥n, zoom y traslaci√≥n,  
- cambios fotom√©tricos (brillo y contraste),  
- estabilidad visual del objeto principal (la flor).

Esta evidencia confirma que el augmentation es realista y contribuye a la robustez del modelo sin destruir la informaci√≥n relevante.

![DA](../assets/ut2_p10_1.png){ width="480" }

---

### 2Ô∏è‚É£ Curvas de Entrenamiento y Validaci√≥n

Se graficaron las curvas de:

- **accuracy (train vs validation)**
- **loss (train vs validation)**

![Curvas](../assets/ut2_p10_2.png){ width="480" }

Las curvas muestran una tendencia estable y sin sobreajuste pronunciado, lo que indica que:

- el augmentations ayud√≥ a generalizar,
- EfficientNetB0 aprendi√≥ de forma progresiva,
- el subset reducido del dataset fue suficiente para entrenar un modelo confiable.

---

### 3Ô∏è‚É£ GradCAM ‚Äì Mapas de Atenci√≥n

Para diferentes im√°genes del conjunto de test, se generaron visualizaciones GradCAM que incluyen:

- Imagen original  
- Mapa de activaci√≥n (heatmap)  
- Overlay de la activaci√≥n sobre la imagen real  

Estas visualizaciones mostraron que el modelo suele enfocarse correctamente en:

- p√©talos,  
- centro de la flor,  
- texturas caracter√≠sticas del patr√≥n floral.

Tambi√©n se detectaron casos donde el modelo se distrae con el fondo, lo que ayuda a interpretar errores y sesgos.

![GradCAM](../assets/ut2_p10_3.png){ width="480" }
---

### 4Ô∏è‚É£ Integrated Gradients ‚Äì Atribuciones por p√≠xel

Se generaron mapas de atribuci√≥n usando IG, que producen explicaciones m√°s granulares que GradCAM.  
En las visualizaciones se observaron:

- contribuciones espec√≠ficas sobre bordes y texturas,  
- detecci√≥n de patrones finos en los p√©talos,  
- √°reas de bajo impacto ignoradas por el modelo.

Este an√°lisis complement√≥ la visi√≥n m√°s global que ofrece GradCAM.

---

En conjunto, todas estas evidencias permitieron analizar:

- desempe√±o cuantitativo del modelo,  
- robustez ante variaciones del dataset,  
- atenci√≥n visual del modelo,  
- y posibles causas de errores en la clasificaci√≥n.

![IntGrad](../assets/ut2_p10_4.png){ width="480" }

## üí° Reflexi√≥n Final

Este pr√°ctico fue uno de los m√°s completos hasta el momento, ya que combin√≥ robustez, rendimiento y explicabilidad: tres pilares fundamentales en el desarrollo de modelos de visi√≥n por computadora que deben utilizarse en entornos reales.

Una de las conclusiones m√°s claras es el enorme impacto que tiene el **data augmentation avanzado**.  
Los modelos no solo mejoraron su accuracy en validaci√≥n, sino que tambi√©n demostraron mayor estabilidad ante perturbaciones visuales. Esto es especialmente relevante en aplicaciones como la identificaci√≥n de flores, donde las im√°genes pueden venir con condiciones de captura muy diversas.  
El augmentation ayud√≥ a mitigar el desbalance natural del dataset y a evitar que el modelo memorice patrones espec√≠ficos de iluminaci√≥n o fondo.

Por otro lado, las t√©cnicas de **explicabilidad** aportaron una capa totalmente distinta de entendimiento.  
GradCAM permiti√≥ ver de forma clara si el modelo estaba enfoc√°ndose realmente en la flor o si se distra√≠a con el entorno. Integrated Gradients, en cambio, ofreci√≥ una mirada m√°s fina sobre qu√© p√≠xeles contribuyen a la predicci√≥n.  
Ambas herramientas fueron clave para detectar casos donde el modelo acertaba por razones equivocadas, o fallaba por prestar atenci√≥n a regiones irrelevantes.

Este aspecto es fundamental en aplicaciones reales:  
un modelo que ‚Äúacierta‚Äù pero por los motivos incorrectos puede ser incluso m√°s peligroso que uno que falla de manera evidente. La explicabilidad permite construir confianza en el proceso de decisi√≥n y validar que el modelo aprende representaciones verdaderamente √∫tiles.

En general, este pr√°ctico fortaleci√≥ mi comprensi√≥n de:

- c√≥mo se construyen pipelines robustos de procesamiento de im√°genes,  
- c√≥mo mejorar modelos con augmentations bien dise√±ados,  
- y c√≥mo interpretar el comportamiento interno de redes profundas mediante t√©cnicas modernas de XAI (*Explainable AI*).

Si contin√∫o explorando este proyecto, me gustar√≠a investigar t√©cnicas adicionales como **CutMix**, **Mixup**, o **test-time augmentation**, adem√°s de probar arquitecturas m√°s grandes como EfficientNetB3 o RegNet. Tambi√©n podr√≠a extender la parte de explicabilidad con herramientas como **LIME** o **SHAP**, aplicadas espec√≠ficamente a im√°genes.

## üìö Referencias

- [Oxford Flowers102 Dataset (TFDS)](https://www.tensorflow.org/datasets/catalog/oxford_flowers102)
- [TensorFlow Data Augmentation (Preprocessing Layers)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)
- [Albumentations ‚Äì Data Augmentation Avanzado](https://albumentations.ai/docs/)
- [Keras Applications ‚Äì EfficientNetB0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0)
- [GradCAM ‚Äì Original Paper](https://arxiv.org/abs/1610.02391)
- [Integrated Gradients ‚Äì Original Paper](https://arxiv.org/abs/1703.01365)
- [Mixup ‚Äì Regularization Technique](https://arxiv.org/abs/1710.09412)
- [CutMix ‚Äì Data Augmentation Technique](https://arxiv.org/abs/1905.04899)
- [TensorFlow Datasets Documentation](https://www.tensorflow.org/datasets)
- [Keras Model Training & Evaluation](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
