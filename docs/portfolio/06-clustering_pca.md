---
title: "Mall Customer Segmentation â€“ Clustering y PCA"
date:
---

# Mall Customer Segmentation â€“ Clustering y PCA

---

## ğŸ“ Contexto

En este prÃ¡ctico trabajÃ© con el **Mall Customer Segmentation Dataset**, un conjunto de datos clÃ¡sico para **segmentaciÃ³n de clientes**.  
El objetivo general fue identificar grupos de consumidores con patrones similares de:

- DemografÃ­a (edad, gÃ©nero)
- Capacidad adquisitiva (ingreso anual)
- Comportamiento de compra (*Spending Score*)

La idea es acercarse a un caso real de marketing en retail, donde el centro comercial quiere:

- Definir **segmentos claros de clientes**
- Ajustar campaÃ±as y promociones
- Optimizar la inversiÃ³n publicitaria
- Detectar perfiles de alto valor vs. bajo engagement

---

## ğŸ¯ Objetivos

En este trabajo busquÃ©:

- Explorar el dataset y comprender sus variables clave.
- Preparar los datos para clustering (codificaciÃ³n, limpieza, escalado).
- Comparar distintos mÃ©todos de **normalizaciÃ³n**: MinMax, Standard y Robust.
- Aplicar **PCA** para reducir dimensionalidad y facilitar la visualizaciÃ³n.
- Evaluar distintas estrategias de **Feature Selection** frente a PCA.
- Entrenar modelos de clustering (principalmente **K-Means**) y elegir el nÃºmero Ã³ptimo de clusters.
- Analizar los segmentos encontrados desde la perspectiva de negocio.

---

## ğŸš€ Desarrollo

### ğŸ” Parte 1 â€” ExploraciÃ³n inicial del dataset

ComencÃ© cargando el **Mall Customer Segmentation Dataset**, verificando su estructura y variables principales:

- *CustomerID*
- *Gender*
- *Age*
- *Annual Income (k$)*
- *Spending Score (1â€“100)*

Este dataset es limpio y no presenta valores faltantes, lo que facilita directamente el anÃ¡lisis.

#### ğŸ“Š Insights preliminares

Durante la exploraciÃ³n inicial observÃ©:

- DistribuciÃ³n relativamente equilibrada entre gÃ©neros.
- Rango amplio de edad (18â€“70 aÃ±os).
- Clientes con ingresos muy variados.
- Spending Score que no presenta correlaciÃ³n lineal directa con el ingreso, lo que sugiere comportamientos diferenciados.

Estos primeros hallazgos justifican el uso de **clustering**, ya que podrÃ­an existir grupos ocultos con patrones de compra similares.

---

### ğŸ§¹ Parte 2 â€” PreparaciÃ³n y escalado de los datos

ProbÃ© distintos mÃ©todos de normalizaciÃ³n para evaluar su impacto en el clustering:

- **StandardScaler** â†’ ajusta segÃºn media y desviaciÃ³n estÃ¡ndar  
- **MinMaxScaler** â†’ lleva todo a un rango entre [0, 1]  
- **RobustScaler** â†’ estable frente a *outliers*

Cada versiÃ³n del dataset escalado se comparÃ³ posteriormente en el proceso de clustering para observar:

- cambios en la separaciÃ³n de los grupos,
- impacto en la forma de las nubes de puntos,
- sensibilidad del algoritmo a la escala de las variables.

#### âœ¨ ObservaciÃ³n clave
El *Spending Score* y el *Annual Income* responden mejor al escalado MinMax y Standard, mientras que la edad presenta mÃ¡s variabilidad, lo que hace Ãºtil tambiÃ©n RobustScaler en algunos escenarios.

---

### ğŸ¨ Parte 3 â€” PCA para visualizaciÃ³n y reducciÃ³n de dimensionalidad

ApliquÃ© **AnÃ¡lisis de Componentes Principales (PCA)** para:

- reducir la dimensionalidad del dataset,
- visualizar grupos potenciales en 2D,
- medir cuÃ¡nto varÃ­a la informaciÃ³n al proyectarla.

#### ğŸ“Œ Resultados de PCA

- Los primeros **2 componentes explican la mayor parte de la varianza**, facilitando la visualizaciÃ³n.
- PCA revelÃ³ estructuras claras entre clientes con:
  - alto ingreso y alto *Spending Score*,
  - bajo ingreso y bajo *Spending Score*,
  - combinaciones intermedias.

Este paso tambiÃ©n sirviÃ³ para comparar PCA vs. Feature Selection tradicional.

---

### ğŸ§© Parte 4 â€” Feature Selection y comparaciÃ³n con PCA

ProbÃ© seleccionar distintas combinaciones de variables:

- Solo *Income* + *Spending Score*
- Agregar *Age*
- Incluir *Gender* codificado

ComparÃ© estos escenarios con la proyecciÃ³n obtenida por PCA.

#### ğŸ“ Conclusiones de esta parte

- PCA logra separar mejor los grupos que cualquier selecciÃ³n manual de variables.
- Sin embargo, la combinaciÃ³n **Income + Spending Score** sigue siendo altamente informativa por sÃ­ misma.
- Agregar *Age* mejora ligeramente algunos lÃ­mites entre clusters, pero no siempre aporta separaciÃ³n fuerte.

---

### âš™ï¸ Parte 5 â€” AplicaciÃ³n de K-Means y bÃºsqueda del nÃºmero Ã³ptimo de clusters

El siguiente paso fue aplicar **K-Means**, el algoritmo de clustering mÃ¡s utilizado para segmentaciÃ³n de clientes.  
Antes de elegir un nÃºmero fijo de clusters, utilicÃ© varios mÃ©todos para determinar el valor Ã³ptimo de *k*.

---

### ğŸ”¢ 5.1 â€” MÃ©todo del Codo (Elbow Method)

ProbÃ© valores de *k* entre 2 y 10 y analicÃ© cÃ³mo disminuÃ­a la **inercia** (suma de distancias intra-cluster).  
El â€œcodoâ€ apareciÃ³ alrededor de **k = 5**, lo que sugiere que:

- agregar mÃ¡s clusters despuÃ©s de 5 no reduce significativamente la inercia,
- el dataset probablemente contiene 5 grupos bien diferenciados.

---

### ğŸ“ˆ 5.2 â€” Silhouette Score

TambiÃ©n calculÃ© el **Silhouette Score** para medir quÃ© tan separados y compactos son los clusters.

- Los puntajes mÃ¡s altos ocurrieron alrededor de **k = 4** y **k = 5**.  
- k=5 mostrÃ³ una separaciÃ³n mÃ¡s equilibrada entre todos los clusters.

Esto reforzÃ³ la elecciÃ³n de **5 clusters** como punto Ã³ptimo.

---

### ğŸ¯ 5.3 â€” K-Means final y anÃ¡lisis de los clusters

EntrenÃ© el modelo final con **k = 5**, usando las mejores variables seleccionadas y los datos escalados.  
Luego analicÃ© cada cluster en funciÃ³n de:

- ingreso anual,
- spending score,
- edad,
- gÃ©nero.

#### ğŸ§© DescripciÃ³n general de los clusters encontrados

Los patrones tÃ­picos fueron:

1. **Clientes jÃ³venes con alto Spending Score y alto ingreso**  
   Segmento premium, ideal para marketing agresivo.

2. **Clientes jÃ³venes con bajo Spending Score pero ingreso medio**  
   Pueden activarse con promociones especÃ­ficas.

3. **Clientes mayores con Spending Score bajo**  
   Grupo estable pero con baja rentabilidad.

4. **Ingresos altos pero Spending Score variable**  
   Segmento con alto potencial de fidelizaciÃ³n.

5. **Ingresos bajos y Spending Score alto**  
   Consumidores sensibles a precio, pero muy activos.

---

### ğŸ¨ VisualizaciÃ³n final de clusters

UsÃ© PCA para proyectar los clusters en 2D, permitiendo ver claramente:

- grupos bien definidos,
- fronteras razonablemente separadas,
- patrones consistentes con las variables originales.

Esto confirmÃ³ que **K-Means fue una buena elecciÃ³n para este dataset**.

---

### ğŸ“ ConclusiÃ³n parcial

- El dataset presenta naturalmente **5 segmentos de clientes**.  
- PCA ayudÃ³ a visualizar y validar la estructura real de los grupos.  
- Los clusters obtenidos pueden usarse directamente para estrategias comerciales, segmentaciÃ³n personalizada y programas de fidelizaciÃ³n.

---

## ğŸ“Š Parte 6 â€” EvaluaciÃ³n de los clusters y anÃ¡lisis de perfiles de cliente

Una vez obtenido el modelo final con **k = 5**, realicÃ© un anÃ¡lisis profundo de cada segmento para entender **quÃ© tipo de clientes representa cada cluster**, cÃ³mo se diferencian entre sÃ­ y quÃ© oportunidades ofrece cada grupo desde la perspectiva de negocio.

---

### ğŸ§¬ 6.1 â€” Perfiles detallados por cluster

Para cada cluster analicÃ©:

- **Edad promedio**
- **Ingreso anual promedio**
- **Spending Score**
- **DistribuciÃ³n por gÃ©nero**

Este anÃ¡lisis permitiÃ³ interpretar los grupos no solo desde lo cuantitativo, sino tambiÃ©n desde comportamientos de consumo.

#### ğŸ·ï¸ Insights principales de los perfiles:

- Hay clusters con **alto gasto y alto ingreso** â†’ clientes VIP.
- Otros tienen **ingreso alto pero bajo gasto** â†’ oportunidad clara para marketing de reactivaciÃ³n.
- Algunos grupos presentan **mayor edad y bajo gasto** â†’ segmentos estables pero poco rentables.
- Los clientes jÃ³venes muestran **gran variabilidad**, desde compradores impulsivos hasta compradores conservadores.

Este tipo de anÃ¡lisis es exactamente lo que un equipo de marketing utilizarÃ­a para **crear campaÃ±as diferenciadas y optimizar inversiÃ³n publicitaria**.

---

### ğŸ“ˆ 6.2 â€” Visualizaciones de soporte

Para entender mejor cÃ³mo se estructuran los segmentos:

- UsÃ© la proyecciÃ³n **PCA 2D** para visualizar cÃ³mo se distribuyen los clusters en el espacio.
- GenerÃ© **grÃ¡ficos de barras** mostrando promedios de edad, ingreso y spending score por cluster.
- AnalicÃ© el tamaÃ±o relativo de cada cluster para entender quÃ© grupos dominan el mercado.

**ConclusiÃ³n visual:** Los clusters estÃ¡n claramente diferenciados, lo que valida que K-Means fue apropiado.

---

### ğŸ§ª 6.3 â€” Silhouette Score por cluster

MÃ¡s allÃ¡ del score general, examinÃ© el **silhouette por cluster**, lo que revelÃ³:

- Clusters con cohesiÃ³n muy alta â†’ clientes con patrones muy homogÃ©neos.
- Clusters con menor cohesiÃ³n â†’ zonas de frontera mÃ¡s difusas, tÃ­picas en datasets reales.
- Pocos valores negativos, indicando **mÃ­nimas asignaciones incorrectas**.

Este anÃ¡lisis ayuda a identificar quÃ© segmentos estÃ¡n mÃ¡s â€œbien definidosâ€ desde la perspectiva algorÃ­tmica.

---

### ğŸš¨ 6.4 â€” DetecciÃ³n de outliers

Utilizando silhouette sample-by-sample pude encontrar:

- Algunos clientes con silhouette < 0 â†’ posibles outliers o compradores atÃ­picos.
- Esto puede deberse a:
  - comportamiento de compra inconsistente,
  - valores extremos en ingreso o gasto,
  - combinaciÃ³n demogrÃ¡fica poco frecuente.

Los outliers no fueron numerosos, lo que sugiere una segmentaciÃ³n estable.

---

### ğŸ§© 6.5 â€” InterpretaciÃ³n final desde negocio

El anÃ¡lisis de clusters permitiÃ³ construir **perfiles accionables**:

- Segmentos VIP donde conviene invertir en fidelizaciÃ³n.
- Segmentos de bajo gasto donde promociones pueden aumentar engagement.
- Segmentos jÃ³venes de alto gasto â†’ ideales para marketing digital.
- Segmentos de bajo ingreso pero alto gasto â†’ sensibles a precio, oportunidad para bundles.

La segmentaciÃ³n ofrece una **visiÃ³n clara y operativa** del comportamiento del cliente dentro del mall.

---

### ğŸ“ ConclusiÃ³n parcial

La fase de evaluaciÃ³n confirmÃ³ que:

- Los **5 clusters** son consistentes, interpretables y Ãºtiles.
- Los perfiles obtenidos muestran diferencias reales y accionables.
- La combinaciÃ³n de K-Means + PCA + anÃ¡lisis cuantitativo permite una segmentaciÃ³n robusta.
- El dataset refleja patrones reales del retail: diversidad de ingresos, edades y hÃ¡bitos de gasto.

---

## ğŸ§  ReflexiÃ³n Final

Este prÃ¡ctico fue uno de los mÃ¡s completos de la unidad, integrando **todo el pipeline de CRISP-DM** aplicado a segmentaciÃ³n de clientes: exploraciÃ³n, preparaciÃ³n, normalizaciÃ³n, clustering, PCA y evaluaciÃ³n. A partir del trabajo realizado, destaco los siguientes aprendizajes y conclusiones.

---

### ğŸ” 1. Sobre la metodologÃ­a CRISP-DM  
- La fase mÃ¡s desafiante fue **Data Preparation**, especialmente decidir cÃ³mo normalizar y quÃ© features dejar para clustering.  
- El **Business Understanding** influyÃ³ directamente en la selecciÃ³n de variables: no todas las que aparecen en el dataset son Ãºtiles para segmentaciÃ³n real.  
- La estructura de CRISP-DM permitiÃ³ mantener un flujo ordenado en un anÃ¡lisis largo y tÃ©cnico.

---

### ğŸ§¹ 2. Data Preparation  
- Entre MinMax, Standard y Robust, el ganador se determinÃ³ empÃ­ricamente usando silhouette score:  
  **el mejor scaler fue el que generÃ³ clusters mÃ¡s cohesivos**.  
- PCA resultÃ³ una herramienta clave para:
  - visualizar estructuras naturales del dataset,  
  - reducir ruido,  
  - verificar si realmente existÃ­an grupos distinguibles.  
- Feature Selection mostrÃ³ que muchas veces **no hace falta usar todas las features** para obtener buenos clusters.

---

### ğŸ¤– 3. Clustering  
- El Elbow Method y Silhouette no siempre coinciden; por eso fue importante complementar con **criterios de negocio** (en retail se suelen esperar 3â€“5 segmentos).  
- K-Means funcionÃ³ muy bien porque los grupos eran relativamente esfÃ©ricos y con separaciÃ³n moderada.  
- Los perfiles obtenidos fueron **interpretable y consistentes**, lo cual es esencial en segmentaciÃ³n comercial.

---

### ğŸ’¼ 4. AplicaciÃ³n real al negocio  
El resultado final permite que un equipo de marketing pueda:

- diseÃ±ar campaÃ±as personalizadas,  
- identificar segmentos de alto valor,  
- detectar clientes con gasto bajo pero alto ingreso (oportunidad clara),  
- optimizar presupuestos de marketing segÃºn comportamiento real.

La segmentaciÃ³n es aplicable en contextos como centros comerciales, e-commerce y programas de fidelidad.

---

### ğŸš€ 5. QuÃ© mejorarÃ­a con mÃ¡s tiempo  
- Probar clustering alternativo para ver si captura estructuras no lineales (DBSCAN, GMM, HDBSCAN).  
- Afinar PCA y Feature Selection para comparar explicabilidad vs rendimiento.  
- AÃ±adir mÃ¡s variables relevantes: visitas al mall, frecuencia de compra, ticket promedio.  
- Evaluar temporalidad â†’ segmentaciÃ³n dinÃ¡mica (clientes que â€œmigranâ€ de un cluster a otro).

---

## ğŸ“¸ Evidencias

[ğŸ“˜ Enlace al Notebook de Google Colab](https://colab.research.google.com/drive/10cXEmzRFMoaXwrZp9vZhRBgZocld-GQy?usp=sharing)

---

## âš¡ Comentarios sobre los Challenges (versiÃ³n breve)

Para no extender el portafolio innecesariamente, dejo solo un resumen general:

- **DBSCAN**: Ãºtil para detectar outliers y clusters de densidad irregular; en este dataset tiende a marcar ruido.  
- **HDBSCAN**: mÃ¡s estable que DBSCAN; forma clusters jerÃ¡rquicos y detecta patrones mÃ¡s complejos.  
- **GMM**: permite clusters elÃ­pticos; interesante alternativa cuando K-Means es demasiado rÃ­gido.  
- **Spectral Clustering**: ideal para estructuras no lineales; requiere buen ajuste de afinidad.  
- **Agglomerative**: da una visiÃ³n jerÃ¡rquica; Ãºtil para interpretar relaciones entre segmentos.  
- **RFE y SFS (Forward/Backward)**: permiten comprender quÃ© features realmente aportan al clustering.  
- **t-SNE / UMAP**: visualizaciones avanzadas â†’ revelan estructuras que PCA no siempre capta.

En general, los challenges enriquecen el anÃ¡lisis y permiten validar que el mÃ©todo elegido (K-Means + escalado adecuado) sÃ­ es razonable para este caso.

---

## ğŸ“š Referencias

![Pandas Documentation](https://pandas.pydata.org/docs/)
![NumPy Documentation](https://numpy.org/doc/)
![Matplotlib Documentation](https://matplotlib.org/stable/)
![Seaborn Documentation](https://seaborn.pydata.org/)
![Scikit-Learn Documentation](https://scikit-learn.org/stable/)
![OneHotEncoder â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)
![K-Means â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
![Silhouette Score â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)
![SequentialFeatureSelector â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)
![PCA â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)
![DBSCAN â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)
![HDBSCAN Documentation](https://hdbscan.readthedocs.io/en/latest/)
![Gaussian Mixture Models â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)
![Spectral Clustering â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html)
![Agglomerative Clustering â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)
![RFE â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)
![Sklearn Datasets](https://scikit-learn.org/stable/datasets/)
![t-SNE â€“ Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)
![UMAP Documentation](https://umap-learn.readthedocs.io/en/latest/)


