---
title: "Segment Anything Model (SAM): Pretrained vs Fine-tuned en Segmentaci√≥n de Inundaciones"
date:
---

# Segment Anything Model (SAM): Pretrained vs Fine-tuned en Segmentaci√≥n de Inundaciones

---

## üìù Contexto

En este pr√°ctico trabaj√© con el modelo **Segment Anything Model (SAM)**, uno de los modelos fundacionales m√°s conocidos para **segmentaci√≥n de im√°genes**. La idea central fue comparar el comportamiento de:

- **SAM pre-entrenado (zero-shot)** sobre un nuevo dominio (inundaciones),
- vs. **SAM fine-tuneado** espec√≠ficamente sobre un dataset de segmentaci√≥n de √°reas inundadas.

El caso de uso est√° vinculado a un escenario real de **respuesta a desastres**:

- Identificar √°reas inundadas en im√°genes satelitales o a√©reas.
- Medir extensi√≥n de agua para apoyo a organismos de emergencia.
- Tener mapas de inundaci√≥n m√°s precisos para planificaci√≥n y mitigaci√≥n.

A diferencia de otros pr√°cticos, ac√° no se trata de clasificar una etiqueta, sino de predecir **m√°scaras de segmentaci√≥n p√≠xel a p√≠xel** sobre im√°genes complejas, donde el agua puede confundirse con sombras, reflejos, nubes u otros elementos visualmente similares.

Todo el pipeline (descarga de dataset, exploraci√≥n, inferencia con SAM pre-entrenado, fine-tuning y evaluaci√≥n) se implement√≥ en Google Colab.

## üéØ Objetivos del Pr√°ctico

En este pr√°ctico trabaj√© con **SAM (Segment Anything Model)** aplic√°ndolo al caso de negocio de **segmentaci√≥n de √°reas inundadas** a partir de im√°genes reales.  
Los objetivos espec√≠ficos fueron:

- Comprender c√≥mo funciona SAM en modo **zero-shot** (pre-entrenado).
- Explorar distintos tipos de **prompts**: point prompts y box prompts.
- Evaluar su desempe√±o en un dominio completamente nuevo.
- Preparar un pipeline para **fine-tuning** del modelo en un dataset espec√≠fico.
- Comparar m√©tricas antes y despu√©s del fine-tuning (IoU, Dice, Precision, Recall).
- Realizar un an√°lisis cualitativo y de errores para identificar mejoras y limitaciones.

---

## ‚öôÔ∏è Setup e Instalaci√≥n

Para este pr√°ctico se instalaron las dependencias necesarias para correr SAM, PyTorch, OpenCV, Albumentations y herramientas de visualizaci√≥n.  
Se configuraron:

- GPU si estaba disponible.
- Seed global para reproducibilidad.
- Librer√≠as SAM (`segment-anything`) y predictores (`SamPredictor`).

Este setup permiti√≥ ejecutar tanto la inferencia zero-shot como el entrenamiento del modelo.

---

## üåä Dataset Utilizado: Flood Area Segmentation

El dataset seleccionado proviene de **Kaggle**, con im√°genes reales de zonas inundadas:

- ~290 im√°genes RGB.
- M√°scaras binarias asociadas (agua vs no agua).
- Ideal para segmentaci√≥n supervisada.
- Representa un caso real de monitoreo de desastres.

La estructura del dataset una vez descomprimido es:

flood_dataset/
‚îú‚îÄ‚îÄ Image/ # Im√°genes originales (.jpg)
‚îú‚îÄ‚îÄ Mask/ # M√°scaras binarias (.png)
‚îî‚îÄ‚îÄ metadata.csv

Se realiz√≥:

- Descarga mediante API de Kaggle.
- Exploraci√≥n de estructura de carpetas.
- Carga de im√°genes y m√°scaras.
- Visualizaci√≥n inicial para validar integridad y variedad del dataset.
- C√°lculo de estad√≠sticas (tama√±os, proporci√≥n de p√≠xeles de agua, etc.).

Todo esto constituy√≥ la base para los experimentos posteriores con SAM.

## üöÄ Desarrollo

### üß† Parte 1 ‚Äî Inferencia con SAM Pre-Entrenado

En esta secci√≥n trabaj√© con el modelo **SAM (Segment Anything Model)** en modo *zero-shot*, es decir, sin ning√∫n tipo de entrenamiento adicional previo.  
El objetivo fue evaluar qu√© tan bien SAM pod√≠a segmentar correctamente √°reas inundadas **sin estar adaptado** a este dominio espec√≠fico.

---

### üîß Carga del Modelo y Predictor

Se utiliz√≥ el checkpoint oficial **`sam_vit_b`**, cargado desde el repositorio original.  
Luego, se cre√≥ un `SamPredictor`, encargado de ejecutar inferencia interactiva.

SAM se prob√≥ usando dos tipos de indicaciones (*prompts*):

- **Point prompts:** un punto dentro de la regi√≥n de agua.
- **Box prompts:** una caja que delimita aproximadamente el √°rea inundada.

Esto permiti√≥ evaluar cu√°nta informaci√≥n necesita el modelo para funcionar correctamente.

---

### üìå Experimentos con Point Prompts

El flujo fue:

1. Seleccionar una imagen real del dataset.
2. Ubicar un punto dentro del √°rea con agua.
3. Pasarlo a SAM como indicaci√≥n.
4. Obtener una m√°scara segmentada y la puntuaci√≥n de confianza.

**Hallazgos:**

- SAM detecta bien zonas de agua marcadas con puntos centrales.
- Tiende a extender la m√°scara m√°s de lo necesario.
- Tiene dificultades en bordes finos y zonas con reflejos.

Se visualizaron:

- Imagen con punto marcado.
- Ground truth de m√°scara real.
- Predicci√≥n de SAM.
- Overlay de la m√°scara para interpretar aciertos y fallos.

---

### üì¶ Experimentos con Box Prompts

Para este caso:

1. Se gener√≥ una bounding box a partir de la m√°scara real.
2. El prompt result√≥ m√°s informativo y preciso que el punto.
3. SAM respondi√≥ con m√°scaras m√°s consistentes y mejor definidas.

**Observaciones:**

- Box prompts reducen significativamente falsos positivos.
- La segmentaci√≥n es m√°s estable que con point prompts.
- Aun as√≠, los bordes pueden ser imprecisos.

Se incluy√≥ un an√°lisis visual comparando ground truth vs predicci√≥n, adem√°s de una vista de diferencias (FP/FN).

---

### üìä M√©tricas Iniciales (Zero-Shot)

Se calcularon las m√©tricas m√°s comunes para segmentaci√≥n:

- **IoU**
- **Dice**
- **Precision**
- **Recall**

Estas evaluaciones iniciales sirvieron de baseline para luego comparar con el modelo fine-tuned.

### üß† Parte 2 ‚Äî Evaluaci√≥n Completa del Modelo Pre-Entrenado (Zero-Shot Benchmark)

Luego de las pruebas iniciales con prompts individuales, se realiz√≥ una evaluaci√≥n cuantitativa completa sobre el *test set* para medir el rendimiento real de SAM en modo zero-shot sobre el dominio de **flood segmentation**.

---

### üìä M√©tricas Evaluadas

Para cada imagen se midieron:

- **IoU (Intersection over Union):** mide superposici√≥n entre predicci√≥n y m√°scara real.
- **Dice Coefficient:** m√°s sensible para segmentaciones con √°reas peque√±as.
- **Precision:** proporci√≥n de p√≠xeles predichos como agua que realmente lo son.
- **Recall:** capacidad del modelo para capturar todas las zonas de agua.

Estas m√©tricas permiten entender diferentes comportamientos:  
- *Precision alta + Recall bajo* ‚Üí el modelo es conservador, no detecta todo.  
- *Recall alto + Precision baja* ‚Üí el modelo se ‚Äúpasa‚Äù, detecta agua donde no la hay.  

---

### üß™ Evaluaci√≥n con Point Prompts

Para cada imagen:

1. Se localiz√≥ un punto dentro del √°rea de agua (ground truth).
2. Se gener√≥ la m√°scara desde SAM usando ese punto.
3. Se calcularon m√©tricas per-image.

**Resultados observados:**

- IoU promedio moderado, con gran variabilidad entre im√°genes.
- Buen desempe√±o en √°reas amplias de agua.
- Fallos m√°s frecuentes en zonas delgadas, r√≠os estrechos o fragmentados.
- Sensibilidad a reflejos y sombras, lo que gener√≥ falsos positivos.

Se graficaron histogramas de distribuci√≥n para entender la dispersi√≥n de resultados.

---

### üì¶ Evaluaci√≥n con Box Prompts

El mismo proceso anterior, pero usando bounding boxes derivadas autom√°ticamente del ground truth.

**Hallazgos clave:**

- IoU y Dice significativamente mejores que con point prompts.
- Mucha menor varianza ‚Üí comportamiento m√°s estable.
- Mejor representaci√≥n de bordes y contornos.
- Reduce falsos negativos, ya que la box delimita mejor la regi√≥n de inter√©s.

---

### üìä Comparaci√≥n Global Point vs Box

Se observ√≥ una tendencia clara:

| Prompt | IoU Promedio | Dice Promedio | Observaciones |
|-------|--------------|----------------|----------------|
| **Point** | Menor | Menor | Altamente dependiente del punto elegido, m√°s ruido |
| **Box** | Mayor | Mayor | M√°s estable y m√°s cercano a la m√°scara real |

Adem√°s, se visualizaron histogramas comparados para IoU, Dice, Precision y Recall, evidenciando que:

- **Los box prompts desplazan la distribuci√≥n completa hacia mejores valores.**
- **El pretrained SAM no est√° adaptado a patrones visuales de inundaci√≥n**, lo cual limita su desempe√±o sin fine-tuning.

---

### üìù Conclusiones de la Evaluaci√≥n Zero-Shot

- SAM es muy poderoso para segmentaci√≥n general, pero **no est√° optimizado para fen√≥menos como inundaciones**, donde:
  - el agua puede tener m√∫ltiples colores,
  - hay reflejos intensos,
  - existen bordes irregulares,
  - hay mucha variabilidad entre escenas.

- **Zero-shot funciona**, pero **no es suficiente para aplicaciones cr√≠ticas**, especialmente en contextos de disaster response.

Esta evaluaci√≥n sirvi√≥ como *baseline* para comparar con el modelo entrenado espec√≠ficamente en el dataset (fine-tuned SAM).

### üß† Parte 3 ‚Äî Preparaci√≥n del Dataset y Fine-Tuning de SAM

Tras evaluar el desempe√±o del modelo pre-entrenado, avanzamos hacia el objetivo principal del pr√°ctico:  
**adaptar SAM al dominio de inundaciones mediante fine-tuning supervisado**.

Esta secci√≥n detalla la construcci√≥n del dataset, normalizaci√≥n, generaci√≥n de prompts autom√°ticos, creaci√≥n de DataLoaders y setup del entrenamiento.

---

### üìÅ 3.1 ‚Äî Construcci√≥n del Dataset Personalizado

SAM no est√° dise√±ado originalmente para entrenarse f√°cilmente; su arquitectura requiere un *workflow* especial:

- Im√°genes deben ser redimensionadas a **1024√ó1024** (tama√±o nativo del encoder de SAM).
- Albumentations se utiliza para aplicar augmentations consistentes entre imagen y m√°scara.
- Se generan prompts autom√°ticos:
  - **Point prompt**: se selecciona un punto aleatorio dentro del agua.
  - **Box prompt**: se deriva del bounding box del ground truth.

El dataset implementa:

- Redimensionamiento fijo  
- Augmentations (flip, rotate, brightness/contrast)  
- Conversi√≥n a tensores PyTorch  
- Generaci√≥n del prompt correspondiente por muestra  
- Retorno de la m√°scara original para m√©tricas posteriores  

Esto permite entrenar SAM con batches peque√±os (1‚Äì4 im√°genes) sin inconsistencias de tama√±o.

---

### üì¶ 3.2 ‚Äî Creaci√≥n de DataLoaders

Los DataLoaders deben manejar prompts variables, por lo que se implement√≥ un `collate_fn` especial.

Puntos clave:

- Todas las im√°genes ya vienen en 1024√ó1024 ‚Üí se pueden apilar sin problemas.
- Los prompts se manejan como listas para preservarlos por individuo.
- `batch_size` bajo (2‚Äì4) debido al alto consumo de memoria del encoder de SAM.
- `shuffle=True` en entrenamiento, `shuffle=False` en validaci√≥n.

Esto garantiza:

- Entrenamiento estable  
- Manejo correcto de prompts  
- M√°xima utilizaci√≥n de GPU sin OOM  

---

### üßÆ 3.3 ‚Äî Funciones de P√©rdida (Loss Functions)

Al ser una tarea de segmentaci√≥n binaria, utilizamos:

- **Binary Cross Entropy (BCE):** buena para clasificaci√≥n pixel a pixel  
- **Dice Loss:** ideal para m√°scaras con clases desbalanceadas (agua vs fondo)

Se define la p√©rdida combinada:

\[
\text{Loss} = 0.5 \cdot BCE + 0.5 \cdot Dice
\]

Esto ayuda al modelo a aprender tanto la localizaci√≥n como la forma completa de la regi√≥n inundada.

---

### üîß 3.4 ‚Äî Configuraci√≥n del Fine-Tuning

Una decisi√≥n cr√≠tica:

#### üîí Congelamos el *image encoder*
Porque:
- Es costoso de entrenar (‚âà300M par√°metros).
- Ya es muy bueno extrayendo caracter√≠sticas generalistas.
- Evitamos sobreajuste con dataset peque√±o.
- Ahorra recursos y acelera el entrenamiento x5‚Äìx10.

#### üî• Entrenamos solo:
- **mask_decoder** ‚Üí responsable de generar m√°scaras finales  
- **parte del prompt encoder** (opcional seg√∫n implementaci√≥n)

Adem√°s:

- **Learning rate** bajo (1e-4) para evitar desestabilizar el decoder.
- **Optimizer:** Adam
- **Scheduler:** StepLR con decay cada 5 epochs

Este setup es est√°ndar para adaptar SAM a dominios especializados.

---

### üéõÔ∏è 3.5 ‚Äî Training Loop

El training loop implementa:

- Forward por imagen individual (SAM no soporta prompts en batch).
- C√°lculo de embeddings congelados.
- Procesamiento de point/box prompts.
- Forward del decoder para predecir la m√°scara.
- Redimensionamiento a 256√ó256 (resoluci√≥n interna del decoder).
- Backpropagation solo sobre par√°metros entrenables.
- C√°lculo de IoU por muestra para monitoreo.

Cada √©poca registra:

- Training loss  
- Validation loss  
- Training IoU  
- Validation IoU  

Se guarda autom√°ticamente el **best model** seg√∫n IoU de validaci√≥n.

---

### üìà 3.6 ‚Äî Resultados del Entrenamiento

El proceso completa:

- Visualizaci√≥n de curvas de p√©rdida
- Visualizaci√≥n de evoluci√≥n de IoU
- Selecci√≥n de mejor checkpoint
- Preparaci√≥n del modelo fine-tuned para la fase de evaluaci√≥n

Estas gr√°ficas permiten validar:

- Si hay overfitting  
- Si el decoder realmente aprende mejores m√°scaras  
- Cu√°nto mejora respecto al modelo pre-entrenado  

SAM fine-tuned tiende a mejorar especialmente en:

- Bordes del agua  
- Regiones delgadas  
- Eliminaci√≥n de falsos positivos por reflejos  
- Detecci√≥n m√°s completa de zonas inundadas  

---

Con esto, el modelo queda listo para pasar a la evaluaci√≥n formal y comparativa.

### üß™ Parte 4 ‚Äî Evaluaci√≥n del Modelo Fine-Tuned y Comparaci√≥n

Tras semanas de hype sobre el poder de SAM, en esta secci√≥n comprobamos realmente qu√© tan bien funciona *antes* y *despu√©s* del fine-tuning en el dominio de inundaciones.

Esta etapa incluye:

- Evaluaci√≥n completa en el conjunto de validaci√≥n  
- C√°lculo de m√©tricas clave (IoU, Dice, Precision, Recall)  
- Comparaci√≥n estad√≠stica Pretrained vs Fine-tuned  
- Visualizaciones cualitativas de mejora  
- An√°lisis de errores (failure cases)

---

### üì• 4.1 ‚Äî Cargar el Mejor Modelo Fine-Tuned

Finalizado el entrenamiento, se carga autom√°ticamente:

- El modelo SAM original  
- Los pesos del mejor checkpoint del decoder  
- Un predictor propio para el modelo fine-tuned

Esto permite comparar *lado a lado* el desempe√±o de ambos modelos sin reconstruir la arquitectura manualmente.

---

### üìä 4.2 ‚Äî Comparaci√≥n Pretrained vs Fine-Tuned (M√©tricas Globales)

Se eval√∫an ambas versiones de SAM sobre todas las im√°genes de validaci√≥n usando **point prompts autom√°ticos**.

M√©tricas:

- **IoU (Intersection over Union):** qu√© tan bien coincide la predicci√≥n con el ground truth  
- **Dice Coefficient:** similar a IoU, m√°s sensible en clases desbalanceadas  
- **Precision:** falsos positivos  
- **Recall:** falsos negativos  

Finalmente se comparan las distribuciones:

- Histogramas Pretrained vs Fine-Tuned  
- Gr√°fico de barras con m√©tricas promedio y mejora porcentual  

Este an√°lisis permite entender no solo si el modelo mejora, sino **cu√°nto** y **d√≥nde**.

---

### üñºÔ∏è 4.3 ‚Äî Visualizaci√≥n Cualitativa de Diferencias

M√°s all√° de los n√∫meros, la parte visual es clave en segmentaci√≥n.

Se muestran para varios ejemplos:

1. Imagen original + punto de prompt  
2. Predicci√≥n del modelo pre-entrenado  
3. Predicci√≥n del modelo fine-tuned  
4. Overlay de ambos modelos sobre la imagen  
5. M√©tricas por imagen (IoU y Dice)

Suelen observarse mejoras claras en:

- Bordes del agua  
- Regi√≥n inundada completa  
- Reducci√≥n de falsos positivos por reflejos o montones de nubes  
- Menor ruido cerca de l√≠mites con tierra firme  

En muchos casos, el fine-tuned recupera √°reas que el SAM base *ni siquiera detectaba*.

---

### üßØ 4.4 ‚Äî An√°lisis de Errores (Failure Cases)

Incluso con fine-tuning, hay desaf√≠os particulares del dominio:

- Reflejos del cielo en agua  
- Sombras profundas  
- Aguas turbias que parecen tierra  
- Zonas inundadas extremadamente finas o mezcladas con vegetaci√≥n  

El an√°lisis detecta:

- Casos donde IoU < 0.3  
- Ancho promedio de la regi√≥n inundada  
- Relaci√≥n agua/fondo  
- Visualizaci√≥n de predicci√≥n vs ground truth  

Finalmente se cuantifica:

- Cu√°ntos *failure cases* ten√≠a el modelo pretrained  
- Cu√°ntos tiene el modelo fine-tuned  
- Cu√°ntos se redujeron (porcentaje)

Esto permite entender si el modelo est√° realmente listo para aplicaciones cr√≠ticas (spoiler: casi nunca lo est√° sin un dataset m√°s grande).

---

Con esto queda finalizada toda la etapa de evaluaci√≥n del pr√°ctico, dejando una base s√≥lida para construir la secci√≥n de cierre y reflexiones.

## üß† Reflexi√≥n Final

Para cerrar este pr√°ctico, se presentan una serie de preguntas clave destinadas a analizar cr√≠ticamente el desempe√±o del modelo, entender sus limitaciones y conectar el trabajo pr√°ctico con aplicaciones reales en monitoreo de inundaciones.

Este apartado es fundamental en un contexto acad√©mico y profesional, ya que transforma un ejercicio t√©cnico en un proceso de razonamiento y toma de decisiones informadas.

---

### üìù Preguntas de Reflexi√≥n

#### **1. ¬øPor qu√© el pretrained SAM puede fallar en detectar agua en im√°genes de inundaciones?**

SAM fue entrenado sobre un dataset gigantesco pero *gen√©rico* (SA-1B).  
La variabilidad, reflejos, turbidez, sombras y mezcla con vegetaci√≥n en im√°genes de inundaciones no forman parte sustancial de ese dataset.  
Por lo tanto, el modelo:

- Puede interpretar reflejos de cielo como objetos separados  
- Puede ignorar agua oscura o cubierta por vegetaci√≥n  
- Puede fallar en regiones delgadas o irregulares  
- No entiende el *contexto sem√°ntico* del dominio (qu√© es inundaci√≥n)

Esto explica por qu√© el zero-shot performance es razonable, pero no √≥ptimo.

---

#### **2. ¬øQu√© componentes de SAM decidiste fine-tunear y por qu√©?**

Se decidi√≥:

- **Congelar el image encoder**  
  Porque ya captura buenas representaciones visuales generales y entrenarlo demandar√≠a enormes recursos.

- **Entrenar √∫nicamente el mask decoder**  
  Esto adapta la parte que realmente toma decisiones de segmentaci√≥n.

Congelar reduce riesgos de overfitting y permite adaptar el modelo a un dataset peque√±o (~300 im√°genes).

---

#### **3. ¬øC√≥mo se comparan point prompts vs box prompts para este caso?**

- **Point prompts**: funcionan bien si el punto cae en el agua, pero pueden segmentar demasiado poco o demasiado.  
- **Box prompts**: tienden a ser m√°s estables y generan m√°scaras m√°s completas porque delimitan la regi√≥n objetivo.

En general:

- **Point prompts = sensibilidad alta a la ubicaci√≥n del punto**  
- **Box prompts = resultados m√°s consistentes**, especialmente cuando el agua tiene bordes complejos.

---

#### **4. ¬øQu√© mejoras espec√≠ficas observaste despu√©s del fine-tuning?**

El fine-tuning produjo mejoras notables:

- Mayor cobertura del √°rea inundada  
- Mejora significativa en bordes  
- Reducci√≥n de falsos positivos por reflejos  
- Mejor discriminaci√≥n entre agua y tierra oscura  
- IoU y Dice aumentaron en pr√°cticamente todos los casos  
- Mucha reducci√≥n de failures (<40% IoU)

El modelo aprende ‚Äúqu√© es agua‚Äù en este dominio espec√≠fico.

---

#### **5. ¬øEst√° listo para deployment en un sistema de respuesta a desastres?**

A pesar de la mejora:

**No totalmente.**

Faltan:

- Dataset m√°s amplio y diverso (varios pa√≠ses, estaciones del a√±o, resoluciones satelitales, variabilidad extrema)  
- Integraci√≥n con post-procesamiento geoespacial  
- Validaci√≥n operativa  
- Robustez ante im√°genes ruidosas, nubes, lluvia, humo  
- Inferencia m√°s r√°pida (SAM no es ideal para producci√≥n)

El modelo es un buen *prototipo*, pero no un sistema productivo final.

---

#### **6. ¬øC√≥mo cambiar√≠a tu approach con 10√ó m√°s datos? ¬øY con 10√ó menos?**

**Con 10√ó m√°s datos (~3000 im√°genes):**

- Descongelar parcialmente el image encoder  
- Aumentar epochs  
- Hacer stratified sampling  
- Entrenar con prompts variados (point + box + mask)  
- Posible uso de EfficientSAM para velocidad

**Con 10√ó menos datos (~30 im√°genes):**

- Usar fuert√≠simo data augmentation  
- Solo fine-tuning del decoder  
- Usar few-shot prompting  
- Congelar completamente todos los encoders  
- Considerar modelos m√°s livianos como MobileSAM

---

#### **7. ¬øQu√© desaf√≠os presenta la segmentaci√≥n de inundaciones?**

La inundaci√≥n es un problema dif√≠cil por factores visuales y ambientales:

- Reflejos del cielo ‚Üí confunden los modelos  
- Sombras de edificios o √°rboles  
- Aguas turbias que parecen tierra  
- Vegetaci√≥n flotante  
- L√≠mites difusos y bordes irregulares  
- Iluminaci√≥n inconsistente  
- Resoluciones variables de c√°maras y sat√©lites  
- Regiones muy delgadas o parcialmente ocultas

Esto hace que la segmentaci√≥n de inundaciones sea un caso ideal para aplicar fine-tuning.

---

Con estas reflexiones se cierra el an√°lisis conceptual del pr√°ctico, integrando tanto los resultados t√©cnicos como la comprensi√≥n del contexto de aplicaci√≥n.

## üì∏ Evidencias

Debido a la complejidad del pr√°ctico (entrenamiento pesado, m√∫ltiples visualizaciones, curvas, comparaciones y an√°lisis extensos), se incluye directamente el enlace al notebook completo donde se ejecuta todo el pipeline:

[üìò Ver Notebook en Google Colab](https://colab.research.google.com/drive/15vU8h89sjUe4WEDGC_wM3nTPlEiQThHi?usp=sharing)

Este notebook contiene:

- Descarga y preparaci√≥n del dataset  
- Inferencia zero-shot con SAM (punto y caja)  
- M√©tricas completas (IoU, Dice, Precision, Recall)  
- Fine-tuning del mask decoder  
- Curvas de entrenamiento  
- Comparaci√≥n cuantitativa y cualitativa  
- An√°lisis de failures  
- Visualizaciones detalladas del modelo antes y despu√©s del fine-tuning  

---

## üìö Referencias

![SAM Paper](https://arxiv.org/abs/2304.02643)  
![Segment Anything - GitHub](https://github.com/facebookresearch/segment-anything)  
![Flood Area Segmentation Dataset](https://www.kaggle.com/datasets/faizalkarim/flood-area-segmentation)  
![Albumentations Documentation](https://albumentations.ai/docs/)  
![PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  
![scikit-image Documentation](https://scikit-image.org/docs/stable/)  
![OpenCV Documentation](https://docs.opencv.org/)  
![SAM HQ](https://github.com/SysCV/sam-hq)  
![FastSAM](https://github.com/CASIA-IVA-Lab/FastSAM)  

---

## üèÅ Cierre del Pr√°ctico

Este pr√°ctico permiti√≥ explorar:

- **SAM pretrained vs fine-tuned** en un caso real de segmentaci√≥n de inundaciones  
- **Prompt engineering** aplicado a segmentaci√≥n (punto, caja)  
- **M√©tricas robustas** de segmentaci√≥n  
- **Curvas de entrenamiento y validaci√≥n**  
- **An√°lisis profundo de errores**  
- **Impacto del fine-tuning** en performance y robustez  

El resultado es un pipeline profesional y completamente reproducible, aplicable a casos de monitoreo ambiental, emergencias y sistemas de visi√≥n geoespacial.

