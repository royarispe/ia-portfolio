---
title: "Fine-tuning de Transformers para Clasificaci√≥n Ofensiva"
date:
---

# Fine-tuning de Transformers para Clasificaci√≥n Ofensiva (Tweets financieros)

---

## üìù Contexto

En este pr√°ctico explor√© el salto desde los modelos cl√°sicos basados en **TF-IDF + regresi√≥n log√≠stica** hacia modelos modernos basados en **Transformers**, aplicados al an√°lisis de sentimiento ofensivo en textos cortos.

El dataset elegido proviene de *Hugging Face Datasets* y contiene tweets financieros en ingl√©s etiquetados en tres clases:

- **0 = Bearish** (sentimiento negativo)
- **1 = Bullish** (sentimiento positivo)
- **2 = Neutral**

La tarea consiste en construir un pipeline completo: desde el EDA inicial, pasando por un baseline cl√°sico, hasta el fine-tuning de un Transformer especializado en lenguaje financiero, evaluando mejoras y comparando enfoques.

---

## üéØ Objetivos

En este pr√°ctico busqu√©:

- Cargar, normalizar y explorar datasets textuales con *datasets*.
- Visualizar patrones mediante n-grams, WordClouds y proyecciones con PCA/UMAP.
- Construir un **baseline cl√°sico** con TF-IDF + Logistic Regression.
- Entrenar un **Transformer** (FinBERT u otros) mediante fine-tuning.
- Comparar m√©tricas entre enfoques tradicionales y modelos modernos.
- Evaluar desbalance de clases y su impacto en la m√©trica macro-F1.
- Analizar errores y observar comportamientos de los modelos durante el entrenamiento.

## üöÄ Desarrollo

### üß© Parte 1 ‚Äî Carga y Exploraci√≥n del Dataset

Para esta primera etapa trabaj√© con el dataset *Twitter Financial News Sentiment*, proveniente de Hugging Face.  
El objetivo fue preparar un dataset homog√©neo con columnas **text** y **label**, para facilitar el pipeline posterior.

### üîç Carga del dataset

Utilic√© `load_dataset()` indicando correctamente la ruta del repositorio:

```python
raw, source_name = load_financial_news()
```

### üìä EDA Inicial

Luego normalic√© las columnas necesarias, ya que distintos datasets pueden llamar al texto de forma distinta (`"text"`, `"tweet"`, `"content"`, etc.).  
Esto permiti√≥ dejar un dataframe consistente:

- **text**: contenido del tweet  
- **label**: 0 = Bearish, 1 = Bullish, 2 = Neutral  

Una vez normalizado, realic√©:

- Distribuci√≥n de clases  
- Distribuci√≥n de longitudes (tokens por tweet)  
- Revisi√≥n de posibles outliers  
- Verificaci√≥n de balance/imbalance  

Los gr√°ficos mostraron que la clase **Neutral** es la m√°s frecuente, lo que implica:

- Utilizar **macro-F1** como m√©trica principal  
- Tener precauci√≥n con modelos sesgados hacia la clase mayoritaria  

El histograma de longitudes mostr√≥ que la mayor√≠a de los tweets tienen entre **10 y 25 tokens**, lo que facilita el trabajo del tokenizer sin truncamientos agresivos.

---

### üß© N-grams y WordClouds

Luego gener√©:

- Top **n-grams (1,2)** por clase usando *CountVectorizer*  
- **WordClouds** por clase para visualizar patrones sem√°nticos  

Esto permiti√≥ observar t√©rminos clave por sentimiento financiero, como:

- **Bearish**: "drop", "loss", "bearish"  
- **Bullish**: "up", "gain", "bullish"  
- **Neutral**: "market", "report", "fed"  

Estas se√±ales resultan √∫tiles para comparar luego el rendimiento del modelo cl√°sico vs. Transformers.

### üß™ Baseline Cl√°sico: TF-IDF + Logistic Regression

Antes de avanzar a modelos Transformer, constru√≠ un **baseline tradicional** para tener un punto de comparaci√≥n.  
Este enfoque utiliza:

- **TF-IDF** como representaci√≥n del texto
- **Logistic Regression** como clasificador lineal multiclase

El pipeline completo fue:

1. **Split estratificado** en train/test  
2. **TF-IDF** con n-grams (1,2) y un m√°ximo de vocabulario configurado  
3. Entrenamiento del modelo  
4. Reporte de m√©tricas y matriz de confusi√≥n  

Los resultados mostraron que:

- El modelo captura bien patrones de palabras frecuentes   
- Tiende a confundir **Neutral** con **Bullish/Bearish**, especialmente cuando el tweet es ambiguo  
- La m√©trica **macro-F1** refleja mejor el desempe√±o real dado el desbalance de clases  

Este baseline sirve como **referencia m√≠nima** para evaluar si el Transformer realmente aporta mejoras significativas.

### ü§ñ Fine-tuning con Transformers (Hugging Face)

Luego del baseline, avanc√© al enfoque moderno: **fine-tuning de un modelo Transformer preentrenado**, espec√≠ficamente modelos orientados al dominio financiero como *FinBERT*, y alternativas gen√©ricas como *RoBERTa* o *BERT base*.

#### üîß Preparaci√≥n del dataset

El dataset se dividi√≥ utilizando `train_test_split` con **estratificaci√≥n**, garantizando que las proporciones de cada clase se mantuvieran iguales en train y test.  
Posteriormente convert√≠ los splits a formato **HuggingFace Dataset**, renombrando la columna `label` a `labels` (requerida por Transformers).

Adem√°s establec√≠:

- `num_labels = 3` (Bearish, Bullish, Neutral)
- Casting expl√≠cito a `ClassLabel` para evitar problemas durante el entrenamiento

#### üß∞ Tokenizaci√≥n

Se utiliz√≥ el tokenizer del checkpoint elegido.  
Claves importantes:

- `truncation=True` para limitar la longitud del input  
- `padding=True` para permitir batching eficiente  
- Soporte a BPE, lo que maneja palabras raras, s√≠mbolos financieros, hashtags y emojis  

Tambi√©n inspeccion√© manualmente c√≥mo tokeniza frases ofensivas o ambiguas, para confirmar que el modelo interpreta adecuadamente t√©rminos clave.

#### üèãÔ∏è Entrenamiento

El entrenamiento se realiz√≥ mediante la clase **Trainer**, definiendo:

- `learning_rate`: t√≠picamente 2e-5  
- `batch_size`: entre 8 y 16 dependiendo de VRAM  
- `num_train_epochs`: 3-5  
- `metric_for_best_model="f1"` para priorizar macro-F1  
- `load_best_model_at_end=True`

La funci√≥n `compute_metrics` devuelve:

- Accuracy
- Macro-F1 (cr√≠tico debido al desbalance)

#### üìà Resultados iniciales

Comparado con el baseline TF-IDF:

- El Transformer mejor√≥ significativamente la **macro-F1**, especialmente en clases minoritarias.  
- Captur√≥ dependencias sem√°nticas y contextuales imposibles para el modelo lineal.  
- Mostr√≥ sobreajuste moderado, pero aceptable dada la calidad del dataset.

Estos resultados justifican el uso de Transformers para clasificaci√≥n ofensiva o de sentimiento en dominios especializados como el financiero.

### üìä Visualizaci√≥n de M√©tricas y Comparaci√≥n Final

Con el modelo Transformer ya entrenado, gener√© las curvas de validaci√≥n por √©poca usando los logs del `Trainer`.  
Estas visualizaciones permiten entender:

- C√≥mo evoluciona la **accuracy**
- C√≥mo mejora (o empeora) la **macro-F1**
- Si existe overfitting despu√©s de cierto n√∫mero de √©pocas

Las curvas mostraron un comportamiento estable:  
incremento progresivo hasta estabilizarse alrededor de la √©poca 3‚Äì4, lo cual confirma que el n√∫mero de √©pocas elegido es adecuado.

#### ü•ä Comparaci√≥n: Baseline TF-IDF + LR vs Transformer

Evalu√© ambos modelos sobre el mismo test set:

- **Baseline (TF-IDF + Logistic Regression):** buen rendimiento en la clase mayoritaria, pero pobre en clases minoritarias.
- **Transformer:**  
  - Mejor√≥ sustancialmente la macro-F1  
  - Redujo errores sistem√°ticos (especialmente confundir Bearish ‚Üî Neutral)  
  - Captur√≥ matices contextuales como sarcasmos, expresiones idiom√°ticas y lenguaje financiero

Ejemplo de m√©tricas finales:

- **Baseline:**  
  - Accuracy ‚âà m√°s alta por bias hacia neutro  
  - Macro-F1 ‚âà m√°s baja por mal rendimiento en clases minoritarias  

- **Transformer:**  
  - Accuracy mejor o similar  
  - Macro-F1 **muy superior**, demostrando real capacidad de clasificaci√≥n equilibrada

#### üß† Interpretaci√≥n

La diferencia principal radica en que:

- El modelo cl√°sico solo mira frecuencia de palabras (BoW).
- El Transformer entiende **sem√°ntica contextual**:
  - relaciones entre tokens  
  - sentimiento impl√≠cito  
  - patrones estil√≠sticos  
  - interacciones entre t√©rminos financieros  

Esto vuelve al Transformer la opci√≥n natural para producci√≥n siempre que se disponga de GPU y se necesite robustez frente a ruido del lenguaje real.

### üßæ Conclusiones Finales

Este pr√°ctico permiti√≥ comparar dos enfoques muy distintos para la clasificaci√≥n de sentimiento/ofensividad en texto:

1. **Modelos cl√°sicos (TF-IDF + LR)**
   - R√°pidos, interpretables y eficientes.
   - Limitados para capturar contexto.
   - Tienden a favorecer clases mayoritarias.
   - √ötiles como baseline para entender el dataset.

2. **Transformers (FinBERT / RoBERTa / BERT)**
   - Comprenden sem√°ntica contextual y relaciones entre tokens.
   - Mejoran especialmente la **macro-F1**, clave en datasets desbalanceados.
   - Requieren mayor poder de c√≥mputo, pero ofrecen una mejora clara.

En este caso, el Transformer super√≥ ampliamente al baseline, especialmente en las clases *Bearish* y *Bullish*, donde aparec√≠an m√°s errores del modelo cl√°sico.

El an√°lisis exploratorio previo (EDA, n-grams, WordClouds, PCA/UMAP, etc.) tambi√©n ayud√≥ a revelar la estructura del dataset, informando decisiones como el tama√±o de secuencia, la m√©trica principal y el tipo de modelo a utilizar.

---

### üì∏ Evidencias

[üìò Enlace al Notebook de Google Colab](https://colab.research.google.com/drive/1f-TcN0g_moCMas3dhlh1mWzFM31N5tYN?usp=sharing)

Incluye:
- Carga y normalizaci√≥n del dataset  
- EDA completo  
- Baseline TF-IDF + LR  
- Fine-tuning del Transformer  
- Curvas de entrenamiento y comparaci√≥n de m√©tricas  

---

### ü§î Reflexiones

**1. ¬øQu√© desaf√≠os presenta este dataset?**  
Tweets cortos, lenguaje ruidoso, jerga financiera, emojis y sarcasmos. Esto afecta el rendimiento del baseline, pero es manejado mejor por Transformers.

**2. ¬øPor qu√© usar macro-F1 en vez de accuracy?**  
Porque la clase *Neutral* domina el dataset, y accuracy puede ocultar fallos graves en clases minoritarias.

**3. ¬øQu√© modelo elegir√≠a para producci√≥n?**  
El Transformer, siempre que haya GPU disponible. Ofrece mejores predicciones equilibradas y maneja mejor lenguaje ambiguo.

**4. ¬øQu√© mejorar√≠a como siguiente paso?**  
- M√°s limpieza y normalizaci√≥n del texto  
- T√©cnicas de data augmentation para texto  
- Incluir embeddings financieros espec√≠ficos (Word2Vec entrenado en corpus financiero)  
- Probar modelos multiling√ºes para tweets mezclados EN/ES  

**5. ¬øQu√© aprend√≠?**  
Que el an√°lisis exploratorio es clave antes de entrenar cualquier modelo, y que los Transformers son claramente superiores cuando el contexto sem√°ntico importa.

---
