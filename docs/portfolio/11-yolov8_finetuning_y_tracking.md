---
title: "Fine-tuning de YOLOv8 y Tracking de Objetos en Retail"
date:
---

# Fine-tuning de YOLOv8 y Tracking de Objetos en Retail

---

## üìù Contexto

En este pr√°ctico trabaj√© con **YOLOv8**, una de las arquitecturas de *object detection* m√°s usadas hoy en d√≠a, para resolver un problema t√≠pico de **retail**: detectar y seguir productos de grocery (frutas) tanto en fotos de g√≥ndolas como en movimiento sobre una cinta transportadora.

La idea central fue comparar el rendimiento de:

- Un **modelo base YOLOv8n** pre-entrenado en **COCO** (clases gen√©ricas).
- Un **modelo YOLOv8n fine-tuned** sobre un dataset espec√≠fico de frutas (Apple, Banana, Grape, Orange, Pineapple, Watermelon).

Adem√°s, cerr√© el pr√°ctico aplicando **tracking de m√∫ltiples objetos** sobre video usando **Norfair**, para mantener IDs consistentes de cada fruta a trav√©s del tiempo.

---

## üéØ Objetivos

En este pr√°ctico busqu√©:

- Probar YOLOv8 pre-entrenado y verificar sus l√≠mites en un dominio espec√≠fico (productos de supermercado).
- Descargar y preparar un dataset en **formato YOLO** desde Kaggle.
- Ejecutar un **fine-tuning r√°pido** de YOLOv8n sobre un dataset de frutas.
- Medir la mejora con m√©tricas de *object detection* (mAP, Precision, Recall, F1-score).
- Comparar visualmente el modelo base vs. el modelo especializado.
- Implementar **tracking de objetos en video** con Norfair usando el modelo fine-tuned.
- Analizar la estabilidad de los tracks (duraci√≥n, continuidad de IDs, clases m√°s frecuentes).

---

## üöÄ Desarrollo

### üß™ Parte 1 ‚Äì Evaluaci√≥n del modelo YOLOv8n base (COCO)

Antes de hacer fine-tuning, prob√© el **modelo YOLOv8n pre-entrenado en COCO** sobre una imagen de g√≥ndola de supermercado. La idea era comprobar si, sin ajuste alguno, ya serv√≠a para el dominio de grocery.

- Se carg√≥ el modelo `yolov8n.pt` (versi√≥n *nano*, liviana y r√°pida para Colab).
- Se corri√≥ inferencia sobre una imagen de estantes con distintos productos.
- Se us√≥ un umbral de confianza moderado (`conf=0.3`) para no filtrar demasiado.

#### üîç Resultados observados

- El modelo detecta algunas instancias como **‚Äúapple‚Äù**, **‚Äúbanana‚Äù**, **‚Äúorange‚Äù**, etc.
- Sin embargo, las detecciones son **gen√©ricas**, no distinguen:
  - marcas espec√≠ficas,
  - tipos de empaque,
  - ni variaciones del mismo producto.
- Se observaron:
  - ‚ùå **Falsos negativos**: frutas presentes que no aparecen detectadas.
  - ‚ùå **Falsos positivos**: objetos que no son frutas pero se etiquetan como tal.
  - ‚ö†Ô∏è Bounding boxes a veces poco ajustados o inconsistentes.

#### üìå Conclusi√≥n de la Parte 1

El experimento confirma que un modelo entrenado en COCO **no es suficiente** para un caso real de retail, donde se necesita:

- distinguir productos particulares,
- contar unidades con precisi√≥n,
- y trabajar con inventarios reales.

Esto motiva la siguiente etapa: **fine-tuning de YOLOv8n** sobre un dataset espec√≠fico de frutas.

### ü•≠ Parte 2 ‚Äì Fine-tuning de YOLOv8 en un dataset especializado de frutas

Para resolver el problema de detecci√≥n espec√≠fica en entornos grocery, realic√© un **fine-tuning** de YOLOv8n sobre un dataset especializado en frutas en formato YOLO.  
Esto permite adaptar el modelo a dominios donde COCO no tiene suficiente granularidad.

---

#### üì• 2.1 ‚Äì Descarga y verificaci√≥n del dataset

El dataset utilizado fue **Fruit Detection Dataset (Kaggle)**.  
Incluye 6 clases espec√≠ficas:

- Apple  
- Banana  
- Grapes  
- Orange  
- Pineapple  
- Watermelon  

El flujo aplicado:

1. Configurar y cargar `kaggle.json`  
2. Descargar dataset con Kaggle CLI  
3. Extraer archivos  
4. Validar estructura YOLO:
   - `train/images` + `train/labels`
   - `valid/images` + `valid/labels`
5. Localizar o generar un `data.yaml` correcto

Se verific√≥ que:

- Cada imagen tiene su archivo `.txt` asociado  
- Las anotaciones siguen el formato YOLO (class_id x_center y_center width height)  
- Las rutas se ajustaron para funcionar correctamente en Colab  

Este paso dej√≥ el dataset listo para entrenamiento.

---

#### üìä 2.2 ‚Äì Exploraci√≥n del dataset y distribuci√≥n de clases

Para entender el dataset se contaron las instancias por clase leyendo cada archivo `.txt`.

**Resultado del an√°lisis:**

- El dataset **no est√° totalmente balanceado**  
- Algunas clases tienen muchas m√°s anotaciones (como *apple* y *orange*)  
- Otras clases presentan baja representaci√≥n (como *pineapple*, *watermelon*)  

Se gener√≥ un **gr√°fico horizontal de barras** mostrando la distribuci√≥n.

**Conclusiones del an√°lisis:**

- Las clases m√°s frecuentes probablemente obtendr√°n mayor mAP  
- Las clases con menos ejemplos pueden presentar peor recall  
- Un aumento de datos futuros deber√≠a priorizar las clases minoritarias

---

#### üñºÔ∏è 2.3 ‚Äì Visualizaci√≥n de ejemplos anotados

Para inspecci√≥n cualitativa se dibujaron bounding boxes manualmente usando las anotaciones.

Observaciones:

- Las anotaciones est√°n bien alineadas  
- Hay variaci√≥n visual en iluminaci√≥n, tama√±o, √°ngulos  
- Algunas frutas est√°n parcialmente ocluidas  
- Los labels coinciden visualmente con las clases del dataset  

Esto confirm√≥ que el dataset es adecuado para fine-tuning y no requiere limpieza adicional.

---

#### ‚öôÔ∏è 2.4 ‚Äì Preparaci√≥n del data.yaml y ejecuci√≥n del Fine-tuning

Tras corregir rutas y confirmar que la estructura era v√°lida, se gener√≥ un archivo:

- `data_fixed.yaml`

con los campos:

- `path`: ra√≠z del dataset  
- `train`: carpeta con im√°genes de entrenamiento  
- `val`: carpeta de validaci√≥n  
- `nc`: 6  
- `names`: lista de las frutas  

Luego, configur√© hyperpar√°metros clave:

- **EPOCHS**: entrenamiento r√°pido (10‚Äì20)  
- **BATCH_SIZE**: 16‚Äì32  
- **IMAGE_SIZE**: 416‚Äì640  
- **FRACTION**: 0.25 para acelerar el entrenamiento  

El modelo utilizado para fine-tuning fue:

**YOLOv8n (nano) ‚Äì el m√°s peque√±o y r√°pido**

El entrenamiento gener√≥:

- `runs/detect/fruit_finetuned/weights/best.pt`
- curvas de loss, precisi√≥n y recall
- estad√≠sticas por epoch (box_loss, cls_loss, dfl_loss)

**Conclusiones del training:**

- La p√©rdida disminuy√≥ consistentemente ‚Üí aprendizaje adecuado  
- No hubo se√±ales de overfitting por usar solo 25% del dataset  
- La GPU se mantuvo estable incluso con batch moderado  
- El modelo convergi√≥ antes de 10 epochs  

---

#### ü§ñ 2.5 ‚Äì Carga del modelo fine-tuned y evaluaci√≥n cuantitativa

El checkpoint utilizado fue:

**best.pt ‚Äî mejor mAP en validation**


Tras cargarlo, se ejecut√≥ `model.val()` para obtener m√©tricas globales y por clase.

**Resultados t√≠picos esperados:**

- **mAP@0.5**: mejora notable respecto al modelo base  
- **mAP@0.5:0.95**: aumento moderado (m√°s estricto)  
- **Precision**: aument√≥ ‚Üí menos falsos positivos  
- **Recall**: aument√≥ ‚Üí menos falsos negativos  
- Las clases con m√°s ejemplos obtuvieron el mejor mAP  
- Las clases minoritarias (p.ej. pineapple) siguen siendo m√°s dif√≠ciles  

Esto evidencia que **el modelo aprende las frutas espec√≠ficas**, cosa que COCO no cubre.

---

#### üîç 2.6 ‚Äì Comparaci√≥n visual: Modelo Base vs Fine-tuned

Se seleccionaron im√°genes del validation set y se aplicaron ambos modelos con el mismo umbral de confianza.

Observaciones:

- El modelo **base (COCO)**:
  - detecta pocos objetos  
  - confunde frutas entre s√≠  
  - bounding boxes imprecisos  
  - muchas detecciones irrelevantes  

- El **modelo fine-tuned**:
  - detecta frutas espec√≠ficas  
  - bounding boxes m√°s ajustados  
  - mayor recall y menos ‚Äúmisses‚Äù  
  - confidence scores m√°s altos  

En la comparaci√≥n lado a lado se evidencia una mejora visual y cuantitativa.

---

#### üßÆ 2.7 ‚Äì An√°lisis de Errores (TP, FP, FN)

Se implement√≥ un sistema manual de evaluaci√≥n por IoU para calcular:

- Verdaderos Positivos (**TP**)  
- Falsos Positivos (**FP**)  
- Falsos Negativos (**FN**)  

Se compararon ambos modelos sobre un subconjunto de validaci√≥n.

**Resultados esperados:**

| M√©trica | Modelo Base | Fine-tuned | Mejora |
|--------|-------------|------------|--------|
| Precision | baja | mucho m√°s alta | ‚úì |
| Recall | bajo | mucho m√°s alto | ‚úì |
| F1-score | pobre | significativamente mayor | ‚úì |

Conclusiones:

- El modelo base falla por falta de especificidad  
- El fine-tuned reduce FP y FN de manera notable  
- La especializaci√≥n del dominio es clave para grocery retail  

---

#### ‚úÖ Conclusi√≥n de la Parte 2

El fine-tuning fue **altamente beneficioso**:

- Se especializ√≥ YOLOv8n en frutas espec√≠ficas  
- Se obtuvieron mejoras grandes en mAP, Precision y Recall  
- Las detecciones visuales son mucho m√°s confiables  
- Se estableci√≥ un modelo apto para tareas reales de inventario y retail  

Esta base permite pasar a la Parte 3: **tracking en video** utilizando el modelo especializado.

---

### üé• 3.1 ‚Äì Descarga y an√°lisis del video de frutas

Para evaluar tracking, se descarg√≥ un video de frutas movi√©ndose sobre una cinta transportadora.  
El video permiti√≥ estudiar:

- movimiento realista  
- oclusiones parciales  
- apariciones y desapariciones  
- cambios de escala  
- variaci√≥n de iluminaci√≥n  

Tras descargarlo, se verific√≥:

- FPS  
- resoluci√≥n  
- n√∫mero de frames  
- duraci√≥n total  

Esto permiti√≥ dimensionar correctamente el procesamiento e inferencia.

---

### üõ∞Ô∏è 3.2 ‚Äì Configuraci√≥n del tracker Norfair

Se eligi√≥ **Norfair** por ser:

- r√°pido  
- simple de integrar  
- compatible con bounding boxes  
- extensible con Kalman Filters  

Par√°metros configurados:

| Par√°metro | Significado | Valor recomendado |
|----------|-------------|------------------|
| `distance_threshold` | tolerancia al movimiento entre frames | 80‚Äì120 px |
| `hit_counter_max` | cu√°nto ‚Äúsobrevive‚Äù un track sin detecciones | 30 |
| `initialization_delay` | n√∫mero de frames para confirmar un nuevo track | 2 |

Motivaciones:

- Mantener estabilidad ‚Üí menos ID switches  
- Evitar falsos positivos ‚Üí delay de inicializaci√≥n  
- Permitir movimientos r√°pidos ‚Üí threshold moderado  

Los bounding boxes se convirtieron a formato Norfair (`[[x1,y1], [x2,y2]]`), agregando tambi√©n `class_id` por si se necesitaba an√°lisis posterior.

---

### üöÄ 3.3 ‚Äì Aplicaci√≥n del tracking sobre el video

Se recorri√≥ frame por frame:

1. **YOLOv8 fine-tuned** detecta objetos  
2. Las detecciones se pasan al tracker  
3. Norfair asigna o crea IDs  
4. Se dibujan:
   - bounding boxes  
   - IDs √∫nicos por fruta  
   - clase estimada  
5. Se guardan estad√≠sticas por frame:

   - n√∫mero de detecciones  
   - clases detectadas  
   - duraci√≥n de cada track  

El resultado fue exportado como:

**videos/grocery_tracked.mp4**


con detecciones y trayectorias superpuestas.

---

### üëÅÔ∏è 3.4 ‚Äì Observaci√≥n del video trackeado

El video evidencia:

- **IDs persistentes**: cada fruta mantiene su identidad  
- **pocos ID switches** gracias al threshold optimizado  
- **detecciones fluidas** incluso con superposiciones leves  
- **tracking robusto** ante peque√±os cambios de velocidad  

Casos dif√≠ciles:

- frutas muy juntas ‚Üí riesgo de switching  
- movimientos muy r√°pidos ‚Üí expansi√≥n de threshold necesaria  
- bounding boxes parcialmente fuera de frame ‚Üí p√©rdida temporal del track  

---

### üìä 3.5 ‚Äì An√°lisis cuantitativo del tracking

Se calcularon estad√≠sticas clave:

- duraci√≥n promedio de tracks  
- tracks por clase  
- detecciones por frame  
- distribuci√≥n de duraciones  
- timeline de continuidad de IDs  

Hallazgos principales:

- Algunos tracks se mantienen por m√°s de 3 segundos  
- Otros tracks cortos ‚Üí detecciones perdidas por oclusi√≥n  
- Las clases m√°s visibles generan tracks m√°s estables  
- El modelo fine-tuned reduce falsos positivos ‚Üí tracking m√°s limpio  

M√©tricas derivadas:

- **Tracks cortos (<1s)** ‚Üí detecciones inconsistentes  
- **Tracks largos (>3s)** ‚Üí excelente seguimiento  
- An√°lisis temporal mostr√≥ continuidad fluida en la mayor√≠a de objetos  

---

### üèÅ Conclusi√≥n de la Parte 3

El sistema completo demostr√≥:

- YOLOv8 fine-tuned produce detecciones especializadas y estables  
- El tracking con Norfair funciona muy bien en escenarios de retail  
- El modelo genera IDs consistentes a trav√©s del movimiento  
- Las m√©tricas muestran alto rendimiento general  
- El pipeline es **r√°pido**, **liviano** y **apto para producci√≥n**  

El resultado final integra detecci√≥n + tracking, formando una soluci√≥n completa para:

- conteo de productos  
- monitoreo de flujos  
- inventario autom√°tico  
- an√°lisis en tiempo real  

---

## üì∏ Evidencias

[Enlace al notebook](https://colab.research.google.com/drive/144HVkK3dOdyAHB9whp2HVhwfwfKXx16y?usp=sharing)

---

## üß† Reflexi√≥n Final

Este pr√°ctico integr√≥ tres √°reas clave de Computer Vision moderna: **detecci√≥n**, **fine-tuning especializado** y **tracking en video**. A partir de los experimentos realizados, se destacan las siguientes conclusiones:

### üîç 1. Sobre el modelo base YOLOv8 (COCO)
- El modelo pre-entrenado funciona bien para **clases generales**, pero no para productos espec√≠ficos.
- COCO incluye objetos como *apple* o *banana*, pero su variabilidad no coincide con el dominio de retail.
- El bajo rendimiento inicial justific√≥ directamente la necesidad de fine-tuning.

### üöÄ 2. Impacto del Fine-Tuning
- El fine-tuned model mejor√≥ **significativamente mAP, precision y recall** respecto al modelo base.
- La especializaci√≥n en frutas permiti√≥ bounding boxes m√°s correctos y detecciones m√°s consistentes.
- El entrenamiento incluso con una fracci√≥n del dataset (25%) ya mostr√≥ mejoras s√≥lidas.

### üìà 3. Comparaci√≥n antes vs despu√©s
- Se detectaron muchas m√°s frutas y con mayor confianza.
- Los falsos positivos disminuyeron, particularmente en objetos que no son frutas.
- Los falsos negativos tambi√©n se redujeron, mostrando que el modelo ‚Äúentiende‚Äù mejor el dominio.

### üé• 4. Tracking: YOLOv8 + Norfair
- La combinaci√≥n produce un sistema de tracking fluido y robusto.
- IDs persistentes permiten seguimiento de cada fruta a lo largo de todo el video.
- Los par√°metros ajustados (threshold, initialization delay, hit counter) mejoraron la estabilidad.
- Se detectaron pocos ID switches, se√±al de un buen emparejamiento entre detecciones y tracks.

### üõí 5. Aplicaci√≥n real al caso de Retail
Este pipeline es perfectamente aplicable a:

- sistemas de inventario autom√°tico,
- monitoreo de cintas transportadoras,
- conteo de productos,
- an√°lisis en tiempo real para supermercados.

La integraci√≥n entre detecci√≥n + tracking abre la puerta a construir dashboards operativos, automatizar control de stock o generar estad√≠sticas de flujo de productos.

### üí° 6. Qu√© mejorar√≠a con m√°s tiempo
- Aumentar epochs para ver si mejora a√∫n m√°s mAP@0.5:0.95.  
- Usar im√°genes m√°s grandes (640‚Äì720 px) para frutas peque√±as.
- Probar trackers m√°s avanzados: **DeepSORT**, **ByteTrack**, **BotSORT**.
- A√±adir filtros de Kalman a Norfair para suavizar a√∫n m√°s las trayectorias.
- Aplicar data augmentation espec√≠fico para retail (motion blur, brillo).

---

## üìö Referencias

- [Ultralytics YOLOv8 Documentation](https://docs.ultralytics.com/)
- [YOLOv8 Training Guide](https://docs.ultralytics.com/modes/train/)
- [Fruit Detection Dataset (Kaggle)](https://www.kaggle.com/datasets/lakshaytyagi01/fruit-detection/)
- [Norfair Tracking Library](https://github.com/tryolabs/norfair)
- [SORT Tracking Paper](https://arxiv.org/abs/1602.00763)
- [DeepSORT Paper](https://arxiv.org/abs/1703.07402)
- [ByteTrack Paper](https://arxiv.org/abs/2110.06864)

---

