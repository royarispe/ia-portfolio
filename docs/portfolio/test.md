---
title: "PrÃ¡ctica 1: EDA del Titanic en Google Colab"
date: 2025-08-12
---

# PrÃ¡ctica 1: EDA del Titanic en Google Colab

---

## ðŸ“ Contexto

> **Nota:**  
    En esta ocasiÃ³n como primer acercamiento al trabajo con ML, rama de la IA vamos a trabajar con el dataset del [Titanic](https://www.kaggle.com/competitions/titanic/data), de esta forma a travÃ©s de la prÃ¡ctica comenzamos a ponernos manos a la obra para explorar este mundo en auge dentro de la informÃ¡tica.

---

## ðŸŽ¯ Objetivos

Explorar, preparar y utilizar herramientas clave para el aprendizaje durante el curso:

- [Google Colab](https://colab.google/)
- [Kaggle](https://www.kaggle.com/)
- [Pandas](https://pandas.pydata.org/docs/)
- [Numpy](https://numpy.org/doc/stable/)
- [Matplotlib](https://matplotlib.org/stable/users/index)
- [Seaborn](https://seaborn.pydata.org/tutorial.html)

---

## â±ï¸ Actividades y Tiempos Estimados

| Actividad                      | Tiempo      |
|--------------------------------|:----------:|
| **Tarea 1:** Setup en Colab    | 5 min      |
| **Tarea 2:** Cargar dataset    | 5-10 min   |
| **Tarea 3:** Conocer dataset   | 10 min     |
| **Tarea 4:** EDA visual        | 15 min     |
| **Tarea 5:** Preguntas finales | â€”          |

---

## ðŸš€ Desarrollo

### Tarea 1 âœ… - Setup en Colab

> [documentaciÃ³n](https://colab.research.google.com/#scrollTo=vwnNlNIEwoZ8)  

Si bien el prÃ¡ctico es muy claro y se comparte el cÃ³digo correspondiente para poder realizarlo de manera muy rÃ¡pida, como mencionÃ© en los objetivos mi idea es empaparme de los temas y aprender realmente por lo cual dentro de esta tarea antes de preparar el setup comencÃ© por leer la [DocumentaciÃ³n](https://colab.research.google.com/#scrollTo=vwnNlNIEwoZ8) para entender quÃ© era esto de Google Colab, a grandes rasgos es un Notebook, "un libro" digital con cÃ³digo dentro, la primera pregunta que me surgiÃ³ es: Â¿por quÃ© lo escribimos y ejecutamos en esta plataforma en vez de en local en mi editor de texto? , la respuesta es sencilla, esos Notebooks primero que nada se almacenan directamente en mi Google Drive, haciendo esto fÃ¡cilmente compartible con compaÃ±eros y es como un Plug and Play, de muy fÃ¡cil uso, pero el verdadero potencial de esto radica en que al ejecutar lo que estoy desarrollando corre en Google Cloud aprovechando las GPU'S y TPU'S de ellos, gracias a esto, aprovechando la potencia del hardware de Google puedo probar todo mucho mÃ¡s rÃ¡pido que utilizando mi mÃ¡quina.

---

### Tarea 2 âœ… - Cargar el dataset de Kaggle

Dataset, no es otra cosa que el conjunto de datos con el cual vamos a trabajar, en este caso, los mismos fueron extraÃ­dos del evento del Titanic, con estos, probaremos las posibilidades, una introducciÃ³n prÃ¡ctica a la parte del anÃ¡lisis de datos, ya que esto es la base de todo lo referido a ML'S e IA'S.

Volviendo a la tarea en particular, seguir el cÃ³digo es lo fÃ¡cil, en lo que me detuve fue en investigar quÃ© es Kaggle, bÃ¡sicamente explotamos el entorno de Google, ya que Kaggle es una plataforma y una comunidad donde aprender, practicar y completar problemas orientados al Data Science, ya que para entrenar modelos, predecir y mÃ¡s la base son los datos que existen a partir de los cuales analizar, buscar patrones y refinar un modelo que prediga el futuro posible. De esta plataforma tomamos los datasets pÃºblicos y disponibles para poder investigar y desarrollar nuestros modelos.

---

### Tarea 3 âœ… - Conocer el dataset

En este caso no habÃ­a mucho que analizar desde cero, ya que dentro del desafio de kaggle te comparten de manera muy detallada cuales son los datos compone el [dataset](https://www.kaggle.com/competitions/titanic/data), quÃ© columnas o atributos, quÃ© nombre identifica cada uno, lo que representa, los valaros puede tomar, etc.

Lo interesante de esta parte fue el probar el cÃ³digo, las funciones disponibles, que acÃ¡ me frene posterior a ver las salidas, para aprender quÃ© se estÃ¡ utilizando, la librerÃ­a de python [Panda](https://pandas.pydata.org/docs/).

Pandas es una librerÃ­a open source, con una gran performance utilizada para todo lo referido a la estructura y el anÃ¡lisis de los datos, esta librerÃ­a nos ayuda a explorar, limpiar y procesar los datos.

La informaciÃ³n que tenemos que manipular (excel, csv, sql, etc) es cargada en una tabla de datos a la cual se la llama como "DataFrame" dÃ¡ndonos la posibilidad tambiÃ©n de exportar los resultados devuelta a un archivo.

Pandas nos da todas las funcionlidades que necesitamos para esta Ã¡rea de la informÃ¡tica, filtrar, seleccionar, extraer y mÃ¡s operaciones con los datos. En conjunto con [Matplotlib](https://matplotlib.org/) otra librerÃ­a la cual se encarga de todo lo que es la creaciÃ³n de visualizaciones estÃ¡ticas, animadas de los datos que procesamos es el combo perfecto para el anÃ¡lisis de los datos.

Como siguiente paso utilcÃ© la CheatSheet de pandas para un paneo general y la [APIReferences](https://pandas.pydata.org/docs/reference/frame.html) para investigar quÃ© hace cada linea que utilicÃ©:

```python
train.shape  # Tupla con filas y columnas
```
Devuelve una tupla con el nÃºmero de las filas y de columnas que tenemos.

```python
train.columns  # Nombres de columnas
```
Devuelve los atributos que tenemos en el DF, lo que quiere decir los nombres de cada columna que tenemos.

```python
train.head(3)  # Primeras 3 filas
```
Devuelve las primeras 3 rows del DF.

```python
train.info()  # Resumen del dataset
```
Nos da un resumen del dataset (este puede ser modificado en funciÃ³n de que parÃ¡metros le pase).

```python
train.describe(include='all').T  # EstadÃ­sticas descriptivas
```
Nos devuelve una descripciÃ³n estadÃ­stica (percentiles, mediana, media, desviaciÃ³n estandar, etc) del DF, al enviar como parÃ¡metro el include "all" este anÃ¡lisis incluye todos los valores de las columnas.

```python
train.isna().sum().sort_values(ascending=False)  # Valores nulos ordenados
```
.isna nos da un output con todos los valores boolean donde, todos los valores NA serÃ¡n True por el contrario serÃ¡n False.

.sum suma la cantidad de elementos que tenemos.

.sort_values(ascending=False): Ordena el output de manera descendiente.

```python
train['Survived'].value_counts(normalize=True)  # ProporciÃ³n de supervivientes
```
En este caso trabajamos con la columna "Survived" y obtenemos un output de la cantidad de supervivientes en formato de proporciÃ³n por el atributo "normalize=True", bÃ¡sicamente del total que porcentaje sobreviviÃ³ y cuÃ¡l no.


```

> Pandas permite manipular, filtrar y analizar datos.  
> Matplotlib y Seaborn ayudan a visualizar los resultados.

---

### Tarea 4 âœ… - EDA visual con Seaborn/Matplotlib

> **Â¿QuÃ© es EDA?**  
> El anÃ¡lisis exploratorio de datos (EDA) usa estadÃ­sticas y visualizaciones para descubrir patrones y preparar los datos para anÃ¡lisis mÃ¡s profundos.

> Seaborn (sobre Matplotlib) facilita la creaciÃ³n de grÃ¡ficos atractivos y el anÃ¡lisis visual.

---

## ðŸ“¸ Evidencias

- Capturas de grÃ¡ficos y outputs
- Enlace al notebook: `p1_eda_titanic.ipynb`
- Resultados obtenidos en la exploraciÃ³n

---

## ðŸ’¡ ReflexiÃ³n

> **ReflexiÃ³n personal:**  
> - QuÃ© aprendiste  
> - QuÃ© mejorarÃ­as  
> - PrÃ³ximos pasos  
>
> *(Completa tu reflexiÃ³n aquÃ­)*

---

## ðŸ“š Referencias

- [Google Colab Docs](https://colab.research.google.com/#scrollTo=vwnNlNIEwoZ8)
- [Kaggle Titanic Competition](https://www.kaggle.com/competitions/titanic/data)
- [Pandas API Reference](https://pandas.pydata.org/docs/reference/frame.html)
- [Matplotlib Docs](https://matplotlib.org/)
- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)